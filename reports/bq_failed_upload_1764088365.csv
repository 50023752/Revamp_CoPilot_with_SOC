run_id,timestamp,question_id,run_number,question,expected_domain,actual_domain,status,reason,latency_seconds,input_tokens,output_tokens,generated_sql,error_message
08209c,2025-11-25 16:25:58.974139+00:00,1,1,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,1.1,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(T1.BUSINESS_DATE, MONTH) AS month,
  COUNT(DISTINCT T1.AGREEMENTNO) AS total_mob4_accounts,
  COUNT(DISTINCT CASE WHEN T1.Bounce_Flag = 'Y' THEN T1.AGREEMENTNO END) AS gns4_bounced_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T1.Bounce_Flag = 'Y' THEN T1.AGREEMENTNO END),
      COUNT(DISTINCT T1.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T1
CROSS JOIN MaxDate
WHERE
  T1.BUSINESS_DATE >= DATE_SUB(MaxDate.max_business_date, INTERVAL '4' MONTH)
  AND T1.MOB_ON_INSTL_START_DATE = 4 /* CRITICAL RULE: Filter for GNS4 */
  AND T1.SOM_NPASTAGEID = 'REGULAR' /* Mandatory Filter: Standard Performance */
  AND T1.SOM_POS > 0 /* Mandatory Filter: Active Accounts */
GROUP BY
  1
ORDER BY
  1 DESC",
08209c,2025-11-25 16:26:11.511650+00:00,1,2,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,1.3,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END) AS gns4_bounced_accounts,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_mob4_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate AS md
WHERE
  t.BUSINESS_DATE >= DATE_SUB(md.max_dt, INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
08209c,2025-11-25 16:26:19.328293+00:00,1,3,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,1.12,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
JOIN MaxDate AS t2
  ON t1.BUSINESS_DATE >= DATE_SUB(t2.max_dt, INTERVAL '3' MONTH)
WHERE
  t1.MOB_ON_INSTL_START_DATE = 4
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
08209c,2025-11-25 16:26:27.559276+00:00,2,1,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.89,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_cases,
  COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END) AS nns3_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.MOB_ON_INSTL_START_DATE = 3 AND t.SOM_NPASTAGEID = 'REGULAR'
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
08209c,2025-11-25 16:26:39.073462+00:00,2,2,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.77,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERID AS dealer_id, /* Assuming 'dealer name' refers to SUPPLIERID as SUPPLIERNAME is not in schema. */
  COUNT(DISTINCT t.AGREEMENTNO) AS total_cases_at_mob_3,
  COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END) AS nns3_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_dt
WHERE
  t.MOB_ON_INSTL_START_DATE = 3 /* CRITICAL RULE: NNS3 is only valid for accounts in their 3rd month */
  AND t.SOM_NPASTAGEID = 'REGULAR' /* Standard Performance (default) */
  AND t.SOM_POS > 0 /* Filter for active accounts */
GROUP BY
  dealer_id
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30 /* Cases are more than 30 per dealer */
ORDER BY
  nns3_percentage DESC
LIMIT 10",
08209c,2025-11-25 16:26:54.382504+00:00,2,3,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.95,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END) AS nns3_cases,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.MOB_ON_INSTL_START_DATE = 3 /* CRITICAL RULE: Required filter for NNS3 calculation */
  AND t.SOM_NPASTAGEID = 'REGULAR' /* Standard performance filter */
  AND t.SOM_POS > 0 /* Filter for active accounts */
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
08209c,2025-11-25 16:27:03.013465+00:00,3,1,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,SKIP,Ref Broken,0.91,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS banking_no_hits,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS banking_no_hit_percentage,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END) AS approved_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  banking_no_hit_percentage DESC
LIMIT 10",
08209c,2025-11-25 16:27:10.300167+00:00,3,2,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,SKIP,Ref Broken,0.82,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS no_banking_hit_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_banking_hit_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  NOT Dealer_Name_Supplier__c IS NULL
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  total_applications > 30
ORDER BY
  no_banking_hit_percentage DESC
LIMIT 10",
08209c,2025-11-25 16:27:19.520367+00:00,3,3,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,SKIP,Ref Broken,0.69,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS banking_no_hits_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS banking_no_hit_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  banking_no_hit_percentage DESC
LIMIT 10",
08209c,2025-11-25 16:27:27.650491+00:00,4,1,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.69,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t1.STATE) AS state,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate
WHERE
  t1.BUSINESS_DATE = MaxDate.max_business_date
  AND UPPER(t1.STATE) = 'ASSAM'
  AND t1.SOM_DPD = 0
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  t1.STATE",
08209c,2025-11-25 16:27:34.551520+00:00,4,2,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.75,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t1.STATE) AS state,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate AS t2
WHERE
  t1.BUSINESS_DATE = t2.max_business_date
  AND UPPER(t1.STATE) = 'ASSAM'
  AND t1.SOM_DPD = 0
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  1",
08209c,2025-11-25 16:27:44.124968+00:00,4,3,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.77,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t.STATE) AS state,
  COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END) AS bounced_0_dpd_accounts,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_0_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_dt
WHERE
  t.SOM_DPD = 0
  AND UPPER(t.STATE) = 'ASSAM'
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1",
08209c,2025-11-25 16:27:56.987321+00:00,5,1,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,SKIP,Ref Broken,1.12,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(CASE WHEN SAFE_CAST(CIBIL_SCORE AS INT64) < 650 THEN 1 END) AS total_applications_cibil_lt_650,
  COUNT(
    CASE
      WHEN SAFE_CAST(CIBIL_SCORE AS INT64) < 650
      AND BRE_Sanction_Result__c IN ('REJECT', 'Reject')
      THEN 1
    END
  ) AS rejected_applications_cibil_lt_650,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN SAFE_CAST(CIBIL_SCORE AS INT64) < 650
          AND BRE_Sanction_Result__c IN ('REJECT', 'Reject')
          THEN 1
        END
      ),
      COUNT(CASE WHEN SAFE_CAST(CIBIL_SCORE AS INT64) < 650 THEN 1 END)
    ) * 100,
    2
  ) AS rejection_rate_cibil_lt_650_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '2' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND NOT SAFE_CAST(CIBIL_SCORE AS INT64) IS NULL /* Exclude rows where CIBIL_SCORE is not a valid number */
GROUP BY
  1
ORDER BY
  1",
08209c,2025-11-25 16:28:05.927184+00:00,5,2,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,SKIP,Ref Broken,1.11,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
08209c,2025-11-25 16:28:15.323413+00:00,5,3,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,SKIP,Ref Broken,1.13,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(CASE WHEN CAST(CIBIL_SCORE AS INT64) < 650 THEN 1 END) AS total_applications_cibil_below_650,
  COUNT(
    CASE
      WHEN CAST(CIBIL_SCORE AS INT64) < 650
      AND BRE_Sanction_Result__c IN ('REJECT', 'Reject')
      THEN 1
    END
  ) AS rejected_applications_cibil_below_650,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN CAST(CIBIL_SCORE AS INT64) < 650
          AND BRE_Sanction_Result__c IN ('REJECT', 'Reject')
          THEN 1
        END
      ),
      COUNT(CASE WHEN CAST(CIBIL_SCORE AS INT64) < 650 THEN 1 END)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '2' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND NOT CIBIL_SCORE IS NULL
GROUP BY
  1
ORDER BY
  1",
08209c,2025-11-25 16:28:33.039243+00:00,6,1,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,SKIP,Ref Broken,0.73,0,0,"WITH FilteredApplications AS (
  SELECT
    BRE_Sanction_Result__c,
    SCORECARD_MODEL_DESCRIPTION_BRE__c
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
)
SELECT
  (
    SELECT
      ROUND(
        SAFE_DIVIDE(
          COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
          COUNT(*)
        ) * 100,
        2
      )
    FROM FilteredApplications
  ) AS overall_rejection_rate_pct,
  BRE_Sanction_Result__c AS rejection_outcome,
  SCORECARD_MODEL_DESCRIPTION_BRE__c AS scorecard_model_description,
  COUNT(*) AS count_of_applications
FROM FilteredApplications
WHERE
  BRE_Sanction_Result__c IN ('REJECT', 'Reject')
GROUP BY
  rejection_outcome,
  scorecard_model_description
ORDER BY
  count_of_applications DESC",
08209c,2025-11-25 16:28:49.082667+00:00,6,2,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,SKIP,Ref Broken,0.26,0,0,"SELECT
  COUNT(*) AS total_applications_in_segment,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_in_segment,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct,
  ARRAY_AGG(
    STRUCT(SCORECARD_MODEL_DESCRIPTION_BRE__c AS rejection_reason, COUNT(1) AS count_of_cases) ORDER BY count_of_cases DESC
    LIMIT 5
  ) FILTER(WHERE
    BRE_Sanction_Result__c IN ('REJECT', 'Reject')
    AND NOT SCORECARD_MODEL_DESCRIPTION_BRE__c IS NULL
    AND SCORECARD_MODEL_DESCRIPTION_BRE__c <> '') AS top_5_rejection_reasons_breakdown
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= '2025-10-01'
  AND DATE(LastModifiedDate) < '2025-11-01'
  AND IS_NUMERIC(CIBIL_SCORE)
  AND CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650","400 Syntax error: Expected end of input but got ""("" at [14:11]; reason: invalidQuery, location: query, message: Syntax error: Expected end of input but got ""("" at [14:11]

Location: asia-south1
Job ID: f63c4c65-113c-4e31-85ab-252ed6a6b2f5
"
08209c,2025-11-25 16:29:11.316101+00:00,6,3,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,SKIP,Ref Broken,0.49,0,0,"WITH FilteredApplications AS (
  SELECT
    BRE_Sanction_Result__c,
    CIBIL_SCORE,
    SCORECARD_MODEL_DESCRIPTION_BRE__c
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
)
SELECT
  COUNT(*) AS total_applications_in_segment,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_in_segment,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct,
  (
    SELECT
      ARRAY_AGG(
        STRUCT(
          COALESCE(reason.SCORECARD_MODEL_DESCRIPTION_BRE__c, 'Unknown/N/A Description') AS rejection_reason_description,
          COUNT(*) AS count_of_rejections
        ) ORDER BY count_of_rejections DESC
      )
    FROM FilteredApplications AS reason
    WHERE
      reason.BRE_Sanction_Result__c IN ('REJECT', 'Reject')
    GROUP BY
      reason.SCORECARD_MODEL_DESCRIPTION_BRE__c
  ) AS rejection_reasons_breakdown /* Breakdown of Rejection Reasons for rejected cases within the segment */
FROM FilteredApplications","400 Unrecognized name: count_of_rejections at [28:20]; reason: invalidQuery, location: query, message: Unrecognized name: count_of_rejections at [28:20]

Location: asia-south1
Job ID: 97e83b96-d7ea-42fd-a61f-67190b1c8528
"
08209c,2025-11-25 16:29:21.984380+00:00,7,1,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.3,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentPortfolio AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_active_accounts_current,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS `1_30_dpd_accounts_current`
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = (
      SELECT
        max_dt
      FROM MaxBusinessDate
    )
    AND SOM_NPASTAGEID = 'REGULAR'
    AND POS > 0
), LastYearPortfolio AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_active_accounts_last_year,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS `1_30_dpd_accounts_last_year`
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = DATE_SUB((
      SELECT
        max_dt
      FROM MaxBusinessDate
    ), INTERVAL '1' YEAR)
    AND SOM_NPASTAGEID = 'REGULAR'
    AND POS > 0
)
SELECT
  ROUND(
    SAFE_DIVIDE(cp.'1_30_dpd_accounts_current', cp.total_active_accounts_current) * 100,
    2
  ) AS current_1_30_dpd_percentage,
  ROUND(
    SAFE_DIVIDE(lyp.'1_30_dpd_accounts_last_year', lyp.total_active_accounts_last_year) * 100,
    2
  ) AS last_year_1_30_dpd_percentage
FROM CurrentPortfolio AS cp
CROSS JOIN LastYearPortfolio AS lyp","400 Syntax error: Unexpected string literal '1_30_dpd_accounts_current' at [34:20]; reason: invalidQuery, location: query, message: Syntax error: Unexpected string literal '1_30_dpd_accounts_current' at [34:20]

Location: asia-south1
Job ID: f7daaed6-47a7-4fb3-ba3f-18cd9c343310
"
08209c,2025-11-25 16:29:35.390117+00:00,7,2,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentPortfolio AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_accounts,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS del_1_30_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = (
      SELECT
        max_dt
      FROM MaxDate
    )
    AND SOM_NPASTAGEID = 'REGULAR'
    AND POS > 0
), LastYearPortfolio AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_accounts,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS del_1_30_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = DATE_SUB((
      SELECT
        max_dt
      FROM MaxDate
    ), INTERVAL '1' YEAR)
    AND SOM_NPASTAGEID = 'REGULAR'
    AND POS > 0
)
SELECT
  'Current Year' AS period,
  ROUND(SAFE_DIVIDE(c.del_1_30_accounts, c.total_accounts) * 100, 2) AS delinquency_1_30_percentage
FROM CurrentPortfolio AS c
UNION ALL
SELECT
  'Last Year' AS period,
  ROUND(SAFE_DIVIDE(l.del_1_30_accounts, l.total_accounts) * 100, 2) AS delinquency_1_30_percentage
FROM LastYearPortfolio AS l",
08209c,2025-11-25 16:29:57.241751+00:00,7,3,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.72,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentPortfolio AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_accounts,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS del_1_30_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = (
      SELECT
        max_dt
      FROM MaxBusinessDate
    )
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
), LastYearPortfolio AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_accounts,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS del_1_30_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = DATE_SUB((
      SELECT
        max_dt
      FROM MaxBusinessDate
    ), INTERVAL '1' YEAR)
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
)
SELECT
  'Current Month' AS period,
  ROUND(SAFE_DIVIDE(c.del_1_30_accounts, c.total_accounts) * 100, 2) AS delinquency_1_30_percentage
FROM CurrentPortfolio AS c
UNION ALL
SELECT
  'Last Year' AS period,
  ROUND(SAFE_DIVIDE(ly.del_1_30_accounts, ly.total_accounts) * 100, 2) AS delinquency_1_30_percentage
FROM LastYearPortfolio AS ly",
08209c,2025-11-25 16:30:03.355655+00:00,8,1,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.75,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1",
08209c,2025-11-25 16:30:09.705197+00:00,8,2,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.74,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.BUSINESS_DATE,
  COUNT(DISTINCT t.AGREEMENTNO) AS cases_slipped_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.dt
WHERE
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
GROUP BY
  t.BUSINESS_DATE",
08209c,2025-11-25 16:30:16.950773+00:00,8,3,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.68,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT t1.AGREEMENTNO) AS cases_slipped_0LY_to_90_plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
INNER JOIN MaxDate AS t2
  ON t1.BUSINESS_DATE = t2.max_business_date
WHERE
  t1.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1 AND t1.SOM_POS > 0",
08209c,2025-11-25 16:30:23.496363+00:00,9,1,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.75,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t1.STATE) AS state,
  COUNT(DISTINCT CASE WHEN t1.DPD_BUCKET = 0 THEN t1.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t1.AGREEMENTNO) AS total_bucket_1_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.DPD_BUCKET = 0 THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate AS t2
WHERE
  t1.BUSINESS_DATE = t2.max_business_date
  AND t1.SOM_DPD_BUCKET = 1
  AND t1.SOM_NPASTAGEID = 'REGULAR'
GROUP BY
  t1.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
08209c,2025-11-25 16:30:32.964718+00:00,9,2,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.77,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_dt
    FROM MaxBusinessDate
  )
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
08209c,2025-11-25 16:30:39.472145+00:00,9,3,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.73,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t1.STATE) AS state,
  COUNT(DISTINCT CASE WHEN t1.DPD_BUCKET = 0 THEN t1.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t1.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.DPD_BUCKET = 0 THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
JOIN MaxDate AS md
  ON t1.BUSINESS_DATE = md.max_business_date
WHERE
  t1.SOM_DPD_BUCKET = 1 AND t1.SOM_NPASTAGEID = 'REGULAR'
GROUP BY
  1
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
08209c,2025-11-25 16:30:46.624363+00:00,10,1,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.68,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
08209c,2025-11-25 16:30:53.701274+00:00,10,2,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.89,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t.STATE) AS state,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate AS md
WHERE
  t.BUSINESS_DATE = md.max_business_date
  AND t.SOM_DPD_BUCKET = 2
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  state
ORDER BY
  roll_forward_rate_percentage DESC
LIMIT 5",
08209c,2025-11-25 16:31:00.582646+00:00,10,3,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(STATE) AS state,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR'
GROUP BY
  state
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
08209c,2025-11-25 16:31:10.219939+00:00,11,1,What is the current 90+ DPD percentage for the entire portfolio?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.8,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS current_90_plus_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
/* CRITICAL RULE: For 90+ DPD Risk analysis, DO NOT filter for SOM_NPASTAGEID = 'REGULAR'. */ /* This ensures the entire portfolio, including bad debt, is considered. */
WHERE
  t.POS > 0",
08209c,2025-11-25 16:31:21.198618+00:00,11,2,What is the current 90+ DPD percentage for the entire portfolio?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.89,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(SAFE_DIVIDE(SUM(NR_90_PLUS), SUM(POS)) * 100, 2) AS current_90_plus_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  ) AND POS > 0",
08209c,2025-11-25 16:31:32.058056+00:00,11,3,What is the current 90+ DPD percentage for the entire portfolio?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.84,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(SAFE_DIVIDE(SUM(t2.NR_90_PLUS), SUM(t2.POS)) * 100, 2) AS current_90_plus_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
CROSS JOIN MaxDate
WHERE
  t2.BUSINESS_DATE = MaxDate.dt
  AND t2.POS > 0 /* Ensure we are calculating for accounts with outstanding principal */ /* CRITICAL RULE: For 90+ DPD (Risk & NPA Analysis), DO NOT apply SOM_NPASTAGEID = 'REGULAR' */",
08209c,2025-11-25 16:31:43.061477+00:00,12,1,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.81,0,0,"SELECT
  DATE_TRUNC(DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_3MOB), SUM(DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_30_plus_delinquency_rate, /* MOB 3 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_6MOB), SUM(DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_30_plus_delinquency_rate, /* MOB 6 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_9MOB), SUM(DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_30_plus_delinquency_rate, /* MOB 9 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_12MOB), SUM(DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_30_plus_delinquency_rate /* MOB 12 Rate for 30+ Delinquency */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  1",
08209c,2025-11-25 16:31:51.347847+00:00,12,2,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.83,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t2.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_3MOB), SUM(t2.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage, /* MOB 3 30+ Delinquency Rate */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_6MOB), SUM(t2.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_percentage, /* MOB 6 30+ Delinquency Rate */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_9MOB), SUM(t2.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_percentage, /* MOB 9 30+ Delinquency Rate */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_12MOB), SUM(t2.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_percentage /* MOB 12 30+ Delinquency Rate */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
JOIN MaxBusinessDate AS m
  ON t2.BUSINESS_DATE = m.max_dt
WHERE
  t2.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  1",
08209c,2025-11-25 16:31:59.349596+00:00,12,3,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.97,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage, /* MOB 3 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_percentage, /* MOB 6 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_percentage, /* MOB 9 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_percentage /* MOB 12 Rate for 30+ Delinquency */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  1",
08209c,2025-11-25 16:32:05.075076+00:00,13,1,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AGREEMENTNO,
  t.BUSINESS_DATE,
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
INNER JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.dt
WHERE
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10",
08209c,2025-11-25 16:32:12.934969+00:00,13,2,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.87,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AGREEMENTNO,
  t.BUSINESS_DATE,
  t.SOM_DPD,
  t.DPD_BUCKET
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND t.POS > 0 /* Ensure it's an active loan with outstanding principal */
LIMIT 10",
08209c,2025-11-25 16:32:18.883662+00:00,13,3,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AGREEMENTNO,
  t.BUSINESS_DATE,
  t.SOM_DPD,
  t.DPD_BUCKET
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
INNER JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.dt
WHERE
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10",
08209c,2025-11-25 16:32:25.288355+00:00,14,1,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS for each?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.97,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.AMTFIN_BAND,
  SUM(t2.NR_90_PLUS) AS total_90_plus_dpd_pos
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
WHERE
  t2.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
GROUP BY
  t2.AMTFIN_BAND
ORDER BY
  total_90_plus_dpd_pos DESC",
08209c,2025-11-25 16:32:33.042329+00:00,14,2,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS for each?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.7,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  SUM(t.NR_90_PLUS) AS total_90_plus_dpd_pos
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  total_90_plus_dpd_pos DESC",
08209c,2025-11-25 16:32:43.242518+00:00,14,3,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS for each?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.67,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  SUM(t.NR_90_PLUS) AS total_90_plus_dpd_pos,
  SUM(t.POS) AS total_pos_in_band,
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS percentage_90_plus_dpd_of_pos
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.POS > 0 /* Only consider accounts with outstanding balance */
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  percentage_90_plus_dpd_of_pos DESC",
