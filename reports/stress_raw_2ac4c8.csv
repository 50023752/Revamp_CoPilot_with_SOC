run_id,timestamp,question_id,run_number,question,expected_domain,actual_domain,status,reason,latency_seconds,input_tokens,output_tokens,generated_sql,error_message
2ac4c8,2025-11-25 21:03:59.546113+00:00,1,1,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data contains all the same rows as the ground truth data. The values are identical, with one minor and acceptable floating-point difference (13.28 vs 13.27). The difference in row order is ignored as per the evaluation criteria.",0.86,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate AS md
WHERE
  t.BUSINESS_DATE >= DATE_SUB(md.max_business_date, INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4 /* Critical rule for GNS4 */
  AND t.SOM_NPASTAGEID = 'REGULAR' /* Standard performance filter */
  AND t.SOM_POS > 0 /* Filter for active accounts */
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:04:17.777762+00:00,1,2,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data contains all the correct rows and values, with only a minor, acceptable floating-point difference for one value (13.28 vs 13.27). The difference in row order is acceptable as the query did not ask for a specific sort order.",1.04,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate
WHERE
  t1.BUSINESS_DATE >= DATE_SUB(MaxDate.max_dt, INTERVAL '4' MONTH)
  AND t1.MOB_ON_INSTL_START_DATE = 4
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:04:36.326725+00:00,1,3,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data contains all the same rows as the ground truth data. The values are identical, with one minor and acceptable floating-point difference (13.28 vs 13.27). The difference in row order is ignored as per the evaluation criteria.",0.75,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE >= DATE_SUB(m.max_dt, INTERVAL '4' MONTH)
WHERE
  t.MOB_ON_INSTL_START_DATE = 4 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:04:54.890688+00:00,1,4,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data contains all the same rows as the ground truth data. The values are identical, with one minor and acceptable floating-point difference (13.28 vs 13.27). The difference in row order is ignored as per the evaluation criteria.",0.87,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE >= DATE_SUB(md.max_dt, INTERVAL '4' MONTH)
WHERE
  t.MOB_ON_INSTL_START_DATE = 4 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:05:10.818509+00:00,1,5,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data contains all the correct rows and values as the ground truth. The minor difference in the percentage for October (13.28 vs 13.27) is within the acceptable precision tolerance. The difference in row order is not a failure as all the correct data points are present.,0.67,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate
WHERE
  t1.BUSINESS_DATE >= DATE_SUB(MaxDate.max_dt, INTERVAL '4' MONTH)
  AND t1.MOB_ON_INSTL_START_DATE = 4
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:05:32.161428+00:00,1,6,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data correctly provides the GNS4 trend for the same months as the ground truth. A minor precision difference of 0.01 for one month is acceptable. The extra columns providing the raw numbers for the percentage calculation are considered helpful context.,0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END) AS gns4_bounced_accounts,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_mob4_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate AS md
WHERE
  t.BUSINESS_DATE >= DATE_SUB(md.max_dt, INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4 /* CRITICAL RULE: Filter for MOB 4 for GNS4 */
  AND t.SOM_NPASTAGEID = 'REGULAR' /* Mandatory filter for standard performance */
  AND t.SOM_POS > 0 /* Mandatory filter for active accounts */
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:05:49.693532+00:00,1,7,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data contains all the correct rows and values as the ground truth. The minor difference in the percentage for October (13.28 vs 13.27) is within the acceptable precision tolerance. The difference in row order is not a failure as all the correct data points are present.,0.67,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate AS t2
WHERE
  t1.BUSINESS_DATE >= DATE_SUB(t2.max_dt, INTERVAL '4' MONTH)
  AND t1.MOB_ON_INSTL_START_DATE = 4
  AND UPPER(t1.SOM_NPASTAGEID) = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:06:08.096948+00:00,1,8,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data contains all the correct rows and values, with only a minor, acceptable floating-point difference for one value (13.28 vs 13.27). The difference in row order is acceptable as the query did not ask for a specific sort order.",0.69,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate AS t2
WHERE
  t1.BUSINESS_DATE >= DATE_SUB(t2.max_dt, INTERVAL '4' MONTH)
  AND t1.MOB_ON_INSTL_START_DATE = 4
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  month
ORDER BY
  month DESC",
2ac4c8,2025-11-25 21:06:28.864749+00:00,1,9,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data contains all the same rows as the ground truth data. The values are identical, with one minor and acceptable floating-point difference (13.28 vs 13.27). The difference in row order is ignored as per the evaluation criteria.",0.87,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxBusinessDate AS m
WHERE
  t.BUSINESS_DATE >= DATE_SUB(m.max_dt, INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:06:46.727623+00:00,1,10,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly provides the GNS4 trend for the same months as the ground truth. The values are identical, with one minor and acceptable floating-point difference (13.28 vs 13.27). The difference in row order is not a failure criterion.",0.83,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate
WHERE
  t.BUSINESS_DATE >= DATE_SUB(MaxDate.dt, INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:07:06.649663+00:00,1,11,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data contains all the same rows as the ground truth data. The values are identical, with one minor and acceptable floating-point difference (13.28 vs 13.27). The difference in row order is ignored as per the evaluation criteria.",0.76,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate
WHERE
  t.BUSINESS_DATE >= DATE_SUB(MaxDate.max_dt, INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:07:24.716671+00:00,1,12,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data contains all the correct rows and values as the ground truth. The minor difference in the percentage for October (13.28 vs 13.27) is within the acceptable precision tolerance. The difference in row order is not a failure as all the correct data points are present.,0.67,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON 1 = 1
WHERE
  t.BUSINESS_DATE >= DATE_SUB(md.max_dt, INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:07:41.860245+00:00,1,13,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data contains all the same rows as the ground truth data. The values are identical, with one minor and acceptable floating-point difference (13.28 vs 13.27). The difference in row order is ignored as per the evaluation criteria.",0.8,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate
WHERE
  t1.BUSINESS_DATE >= DATE_SUB(MaxDate.max_dt, INTERVAL '4' MONTH)
  AND t1.MOB_ON_INSTL_START_DATE = 4
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:08:01.639660+00:00,1,14,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data correctly identifies the GNS4 percentage trend for the same months as the ground truth. A minor precision difference of 0.01 for one month is within the acceptable tolerance. The extra columns provided are supplementary and do not detract from the correct answer.,0.83,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END) AS gns4_bounced_accounts,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_mob_4_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE >= DATE_SUB((
    SELECT
      max_dt
    FROM MaxDate
  ), INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4 /* CRITICAL RULE: Required for GNS4 */
  AND t.SOM_NPASTAGEID = 'REGULAR' /* Mandatory for standard performance metrics */
  AND t.SOM_POS > 0 /* Mandatory for active accounts */
GROUP BY
  month
ORDER BY
  month DESC",
2ac4c8,2025-11-25 21:08:19.634411+00:00,1,15,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data contains all the correct rows and values, with only a minor, acceptable floating-point difference for one value (13.28 vs 13.27). The difference in row order is acceptable as the query did not ask for a specific sort order.",0.87,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate
WHERE
  t.BUSINESS_DATE >= DATE_SUB(MaxDate.max_dt, INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:08:38.749575+00:00,1,16,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data contains all the same rows as the ground truth data. The values are identical, with one minor and acceptable floating-point difference (13.28 vs 13.27). The difference in row order is ignored as per the evaluation criteria.",0.73,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate
WHERE
  t1.BUSINESS_DATE >= DATE_SUB(MaxDate.dt, INTERVAL '4' MONTH)
  AND t1.MOB_ON_INSTL_START_DATE = 4
  AND UPPER(t1.SOM_NPASTAGEID) = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:08:56.344287+00:00,1,17,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data is missing the record for the month '2025-06-01' which is present in the ground truth. Additionally, the 'gns4_percentage' for '2025-10-01' is 13.27 in the candidate data, while it is 13.28 in the ground truth, which is a minor precision difference but contributes to the mismatch when combined with the missing row.",0.69,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate
WHERE
  t1.BUSINESS_DATE >= DATE_TRUNC(DATE_SUB(MaxDate.max_dt, INTERVAL '3' MONTH), MONTH) /* Last 4 months implies current month + 3 prior, so 4 distinct months */
  AND t1.MOB_ON_INSTL_START_DATE = 4
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  month
ORDER BY
  month DESC",
2ac4c8,2025-11-25 21:09:17.123901+00:00,1,18,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data contains all the same rows as the ground truth data. The values are identical, with one minor and acceptable floating-point difference (13.28 vs 13.27). The difference in row order is ignored as per the evaluation criteria.",1.1,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate AS md
WHERE
  t.BUSINESS_DATE >= DATE_SUB(md.max_dt, INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:09:36.613605+00:00,1,19,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly provides the GNS4 trend for the same months as the ground truth. The values are identical, with one minor and acceptable floating-point difference (13.28 vs 13.27). The difference in row order is not a failure criterion.",0.83,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate AS md
WHERE
  t.BUSINESS_DATE >= DATE_SUB(md.max_dt, INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4 /* CRITICAL RULE: Filter for GNS4 */
  AND t.SOM_NPASTAGEID = 'REGULAR' /* Standard performance filter */
  AND t.SOM_POS > 0 /* Active accounts */
GROUP BY
  1
ORDER BY
  1 DESC",
2ac4c8,2025-11-25 21:09:53.026123+00:00,1,20,What is GNS4 trend for last 4 months?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data contains all the correct rows and values as the ground truth. The minor difference in the percentage for October (13.28 vs 13.27) is within the acceptable precision tolerance. The difference in row order is not a failure as all the correct data points are present.,0.82,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS gns4_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate
WHERE
  t.BUSINESS_DATE >= DATE_SUB(MaxDate.max_business_date, INTERVAL '4' MONTH)
  AND t.MOB_ON_INSTL_START_DATE = 4
  AND UPPER(t.SOM_NPASTAGEID) = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  month
ORDER BY
  month DESC",
2ac4c8,2025-11-25 21:10:10.931548+00:00,2,1,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 10 dealers and provides the accurate total cases and NNS3 percentages, matching the ground truth data in all essential values. The difference in column names is acceptable per the evaluation criteria.",1.11,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_nns3_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxBusinessDate AS mbd
WHERE
  t.BUSINESS_DATE = mbd.max_dt
  AND t.MOB_ON_INSTL_START_DATE = 3 /* CRITICAL RULE for NNS3 */
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:10:29.886928+00:00,2,2,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data failed to provide the 'dealer_name' as explicitly requested by the user, returning 'supplierid' instead. Furthermore, the top result from the ground truth ('SAI MOTORS') is completely missing from the candidate's result set, and an extra, incorrect record has been included.",0.74,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERID, /* Assuming SUPPLIERID represents the dealer, as 'DEALERNAME' is not in schema. */
  COUNT(DISTINCT t.AGREEMENTNO) AS total_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.MOB_ON_INSTL_START_DATE = 3 /* Critical rule for NNS3 */
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERID
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:10:50.624647+00:00,2,3,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 10 dealers, their case counts, and NNS3 percentages, matching the ground truth. The presence of an extra, relevant column ('nns3_bounced_cases') is acceptable as per the evaluation criteria.",0.88,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_nns3_eligible_cases,
  COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END) AS nns3_bounced_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t.MOB_ON_INSTL_START_DATE = 3
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:11:11.459285+00:00,2,4,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data failed to provide the 'dealer_name' as explicitly requested by the user, returning 'supplierid' instead. Furthermore, the top result from the ground truth ('SAI MOTORS') is completely missing from the candidate's result set, and an extra, incorrect record has been included.",0.71,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERID,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.MOB_ON_INSTL_START_DATE = 3 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERID
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:11:29.257260+00:00,2,5,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 10 dealers, their total cases, and their NNS3 percentages, matching the ground truth perfectly. The inclusion of the extra 'nns3_cases' column is acceptable as it provides additional helpful context without altering the core correctness of the answer.",0.93,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_accounts_at_mob3,
  COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END) AS nns3_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.MOB_ON_INSTL_START_DATE = 3 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:11:46.320416+00:00,2,6,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data is a perfect match to the ground truth. All rows and corresponding values are identical. The difference in the column name for the case count ('total_cases' vs. 'total_mob3_cases') is acceptable as per the evaluation criteria.,0.84,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.SUPPLIERNAME AS dealer_name,
  COUNT(DISTINCT t2.AGREEMENTNO) AS total_mob3_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t2.NNS3 = 'Y' THEN t2.AGREEMENTNO END),
      COUNT(DISTINCT t2.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
INNER JOIN MaxDate
  ON t2.BUSINESS_DATE = MaxDate.dt
WHERE
  t2.MOB_ON_INSTL_START_DATE = 3
  AND t2.SOM_NPASTAGEID = 'REGULAR'
  AND t2.SOM_POS > 0
GROUP BY
  dealer_name
HAVING
  COUNT(DISTINCT t2.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:12:08.545403+00:00,2,7,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data failed to provide the requested 'dealer_name', showing 'supplierid' instead. Furthermore, the data itself is incorrect as the top result from the ground truth is missing, and an incorrect record has been included at the bottom of the list.",0.68,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t1.SUPPLIERID,
  COUNT(DISTINCT t1.AGREEMENTNO) AS total_mob3_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.NNS3 = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
INNER JOIN MaxDate AS md
  ON t1.BUSINESS_DATE = md.max_business_date
WHERE
  t1.MOB_ON_INSTL_START_DATE = 3
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  t1.SUPPLIERID
HAVING
  COUNT(DISTINCT t1.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:12:24.384667+00:00,2,8,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 10 dealers, their total cases, and NNS3 percentages, matching the ground truth perfectly. The inclusion of an extra, relevant column ('nns3_bounced_cases') is acceptable.",0.68,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_nns3_cases,
  COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END) AS nns3_bounced_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxBusinessDate AS m
WHERE
  t.BUSINESS_DATE = m.max_dt
  AND t.MOB_ON_INSTL_START_DATE = 3
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:12:44.166336+00:00,2,9,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 10 dealers with the highest NNS3 percentage and more than 30 cases. All dealer names, case counts, and percentages match the ground truth. The slight reordering of two dealers with identical metrics is acceptable as it does not affect the correctness of the result set.",0.83,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_mob_3_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_date
WHERE
  t.MOB_ON_INSTL_START_DATE = 3 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:13:01.526370+00:00,2,10,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 10 dealers, their total cases, and their NNS3 percentages, matching the ground truth data exactly. The inclusion of an extra, relevant column ('nns3_cases') is acceptable.",0.76,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_cases,
  COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END) AS nns3_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.MOB_ON_INSTL_START_DATE = 3 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:13:16.567134+00:00,2,11,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data perfectly matches the ground truth data in terms of values, row count, and sorting order. The difference in the column name ('dealer_name' vs. 'suppliername') is acceptable as per the evaluation criteria.",0.74,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.MOB_ON_INSTL_START_DATE = 3 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:13:32.564549+00:00,2,12,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 10 dealers, their total cases, and NNS3 percentages, matching the ground truth perfectly. The inclusion of an extra, relevant column ('nns3_cases') is acceptable.",0.74,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_cases,
  COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END) AS nns3_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
INNER JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.dt
WHERE
  t.MOB_ON_INSTL_START_DATE = 3
  AND UPPER(t.SOM_NPASTAGEID) = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:13:52.199770+00:00,2,13,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. It correctly identifies the top 10 dealers, their case counts, and NNS3 percentages. The minor difference in sorting for rows with identical percentages (4.55) is acceptable as no secondary sort order was specified in the user's question.",0.73,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.SUPPLIERNAME,
  COUNT(DISTINCT t2.AGREEMENTNO) AS number_of_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t2.NNS3 = 'Y' THEN t2.AGREEMENTNO END),
      COUNT(DISTINCT t2.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
CROSS JOIN MaxDate
WHERE
  t2.BUSINESS_DATE = MaxDate.max_business_date
  AND t2.MOB_ON_INSTL_START_DATE = 3 /* Critical rule for NNS3 */
  AND t2.SOM_NPASTAGEID = 'REGULAR' /* Standard exclusion for NNS */
  AND t2.SOM_POS > 0 /* Ensure active accounts */
GROUP BY
  t2.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t2.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:14:15.175052+00:00,2,14,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data failed to provide the 'dealer_name' as requested by the user, returning 'supplierid' instead. This is a critical failure as the primary entity requested is missing. Additionally, the candidate data is missing the top result from the ground truth ('SAI MOTORS') and includes a different record at the bottom of the list.",0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERID,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_mob3_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.MOB_ON_INSTL_START_DATE = 3 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERID
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:14:33.976589+00:00,2,15,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 10 dealers, their total cases, and their NNS3 percentages, matching the ground truth data perfectly. The inclusion of an extra column is acceptable.",1.06,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_nns3_cases,
  COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END) AS nns3_bounced_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate AS md
WHERE
  t.BUSINESS_DATE = md.max_dt
  AND t.MOB_ON_INSTL_START_DATE = 3 /* Critical rule for NNS3 */
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30 /* Filter for cases more than 30 per dealer */
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:14:53.595920+00:00,2,16,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 10 dealers, their case counts, and NNS3 percentages. The values in all rows and columns are semantically equivalent to the ground truth. The minor difference in the order of the last two rows is acceptable as they have tied values for the sorting criteria.",0.81,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_cases_at_mob3,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t.MOB_ON_INSTL_START_DATE = 3
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:15:14.266747+00:00,2,17,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data failed to provide the requested 'dealer_name' and instead returned 'dealer_id'. Furthermore, the data itself is incorrect; the top result from the ground truth ('SAI MOTORS') is missing, and an incorrect record has been included at the bottom of the list.",0.94,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERID AS dealer_id,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate AS md
WHERE
  t.BUSINESS_DATE = md.max_business_date
  AND t.MOB_ON_INSTL_START_DATE = 3 /* CRITICAL RULE: NNS3 is only valid for MOB 3 */
  AND t.SOM_NPASTAGEID = 'REGULAR' /* Mandatory filter for standard performance */
  AND t.SOM_POS > 0 /* Mandatory filter for active accounts */
GROUP BY
  dealer_id
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:15:31.833116+00:00,2,18,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data failed to provide the requested 'dealer_name', showing 'supplierid' instead. Additionally, it displayed 'nns3_cases_count' with incorrect values, rather than the 'total_cases' which was a required filter condition (cases > 30) and a requested output column. The values in the percentage column are also partially incorrect.",0.91,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERID,
  COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END) AS nns3_cases_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.MOB_ON_INSTL_START_DATE = 3 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERID
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:15:49.970488+00:00,2,19,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 10 dealers with the highest NNS3 percentage and more than 30 cases. All dealer names, case counts, and percentages match the ground truth. The minor difference in row order for dealers with the same percentage is acceptable.",0.73,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.SUPPLIERNAME,
  COUNT(DISTINCT t2.AGREEMENTNO) AS total_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t2.NNS3 = 'Y' THEN t2.AGREEMENTNO END),
      COUNT(DISTINCT t2.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
CROSS JOIN MaxBusinessDate AS m
WHERE
  t2.BUSINESS_DATE = m.max_dt
  AND t2.MOB_ON_INSTL_START_DATE = 3 /* CRITICAL RULE for NNS3 */
  AND t2.SOM_NPASTAGEID = 'REGULAR'
  AND t2.SOM_POS > 0
GROUP BY
  t2.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t2.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:16:06.114571+00:00,2,20,Give me top 10 dealer names that have the highest NNS3 percentage and cases are more than 30 per dealer? Show the number of cases.,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 10 dealers, their total cases, and NNS3 percentages, matching the ground truth perfectly. The inclusion of an extra, relevant column ('nns3_cases') is acceptable as it provides helpful context.",0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.SUPPLIERNAME,
  COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END) AS nns3_cases,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_cases,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.NNS3 = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS nns3_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate
WHERE
  t.BUSINESS_DATE = MaxDate.max_business_date
  AND t.MOB_ON_INSTL_START_DATE = 3
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.SUPPLIERNAME
HAVING
  COUNT(DISTINCT t.AGREEMENTNO) > 30
ORDER BY
  nns3_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:16:35.509600+00:00,3,1,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data correctly identifies the top 10 dealers and provides accurate values for all requested metrics. The sorting is correct, and the minor difference in the order of rows with tied 'no_banking_hit_percentage' values is acceptable. The absence of the 'no_banking_hit_applications' column is also acceptable as it was not explicitly requested in the user's question.",0.81,0,0,"SELECT
  `Dealer_Name_Supplier__c`,
  COUNT(*) AS `total_applications`,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS `no_banking_hit_percentage`,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS `approval_percentage`
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
GROUP BY
  `Dealer_Name_Supplier__c`
HAVING
  COUNT(*) > 30
ORDER BY
  `no_banking_hit_percentage` DESC
LIMIT 10",
2ac4c8,2025-11-25 21:16:56.741849+00:00,3,2,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data correctly identifies the top 10 dealers with the highest 'no hit' percentage, adhering to the application count filter. All calculated values, including 'no hit percentage' and 'approval percentage', match the ground truth. The inclusion of an extra, relevant column ('approved_applications') is acceptable.",1.03,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS banking_no_hits,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS banking_no_hit_percentage,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END) AS approved_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  banking_no_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:17:13.454298+00:00,3,3,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data provided a completely different list of top 10 dealers. None of the dealer names or their corresponding metrics (no hit percentage, approval percentage) match the ground truth data.",1.12,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS banking_no_hit_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS banking_no_hit_percentage,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END) AS approved_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH)
  AND DATE(LastModifiedDate) < DATE_TRUNC(CURRENT_DATE, MONTH)
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  total_applications > 30
ORDER BY
  banking_no_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:17:30.976280+00:00,3,4,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data provided a completely different list of top 10 dealers. None of the dealers from the ground truth data are present in the candidate's response. The values for 'no hit percentage' and 'approval percentage' are also entirely different, indicating a fundamental error in data retrieval or calculation.",1.09,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS banking_no_hit_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS banking_no_hit_percentage_pct,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH)
  AND DATE(LastModifiedDate) < DATE_TRUNC(CURRENT_DATE, MONTH)
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  banking_no_hit_percentage_pct DESC
LIMIT 10",
2ac4c8,2025-11-25 21:17:50.632594+00:00,3,5,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data has identified a completely different set of top 10 dealers. None of the dealer names, total applications, no banking hit percentages, or approval percentages match the ground truth data.",0.93,0,0,"SELECT
  t1.Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            t1.FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR t1.FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_banking_hit_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN t1.BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25` AS t1
WHERE
  DATE(t1.LastModifiedDate) >= DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH)
  AND DATE(t1.LastModifiedDate) < DATE_TRUNC(CURRENT_DATE, MONTH)
GROUP BY
  t1.Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  no_banking_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:18:13.690322+00:00,3,6,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data correctly identifies the top 10 dealers and provides accurate values for all requested metrics. The set of dealers and their corresponding data is identical to the ground truth. A minor difference in the sort order for two rows with a tied 'no_hit_percentage' is acceptable as the core data is correct.,1.02,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS no_banking_model_hits,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_hit_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  no_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:18:29.789562+00:00,3,7,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data is completely incorrect. It has identified a different set of top 10 dealers. None of the dealer names or their associated metrics (total applications, no hit percentage, approval percentage) match the ground truth data.",0.93,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS no_banking_hits,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_hit_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH)
  AND DATE(LastModifiedDate) < DATE_TRUNC(CURRENT_DATE, MONTH)
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  no_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:18:49.137576+00:00,3,8,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data is completely incorrect. None of the top 10 dealers listed match the ground truth data. The values for 'no_banking_hit_percentage' and 'approval_percentage' are also entirely different, indicating a fundamental error in the AI's data retrieval and ranking logic.",1.14,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS no_banking_hit_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_banking_hit_percentage,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END) AS approved_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH)
  AND DATE(LastModifiedDate) < DATE_TRUNC(CURRENT_DATE, MONTH)
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  no_banking_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:19:14.231578+00:00,3,9,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data correctly identifies the top 10 dealers and provides the correct values for all requested metrics. The set of dealers and their associated data perfectly match the ground truth. The minor difference in row order for dealers with tied percentages is acceptable as no secondary sort order was specified.,0.78,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS no_banking_hit_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_banking_hit_percentage,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END) AS approved_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  NOT Dealer_Name_Supplier__c IS NULL
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  no_banking_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:19:38.807807+00:00,3,10,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data is correct. It provides the same top 10 dealers with identical values for all metrics as the ground truth. The slight reordering of two dealers with the exact same 'no banking hit percentage' is acceptable as no secondary sort order was specified.,0.8,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS banking_no_hits,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS banking_no_hit_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  banking_no_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:19:56.714274+00:00,3,11,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data correctly identifies the top 10 dealers and provides the correct metrics. The 'no_banking_hit_percentage' is represented as a decimal (e.g., 0.9697) instead of a whole number percentage (e.g., 96.97), which is semantically equivalent. The candidate is missing the 'no_banking_hit_applications' column, but this was not explicitly requested in the final output and does not affect the correctness of the answer.",0.77,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ),
    4
  ) AS no_banking_hit_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  no_banking_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:20:18.729289+00:00,3,12,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data has identified a completely different set of top 10 dealers. None of the top dealers from the ground truth, such as 'Chandra Automobiles' or 'VERMA AUTO SALES 33141', are present in the candidate's list. The values for the metrics (no banking hit percentage, total applications, approval percentage) are also entirely different, indicating a fundamental error in the query's logic for filtering, aggregation, or ranking.",1.13,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END) AS approved_count,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS no_banking_hits,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_banking_hit_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
GROUP BY
  1
HAVING
  COUNT(*) > 30
ORDER BY
  no_banking_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:20:39.621244+00:00,3,13,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data presents a completely different list of top 10 dealers. The dealers, total application counts, no-hit percentages, and approval percentages do not match the ground truth. For example, the top dealer in the ground truth is 'Chandra Automobiles' with a 96.97% no-hit rate, while the candidate's top dealer is 'VARSHA AUTOLINES' with a 95.65% rate. The underlying data for the few matching dealers is also incorrect.",0.95,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS banking_no_hits,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS banking_no_hit_percentage_pct,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END) AS approved_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  banking_no_hit_percentage_pct DESC
LIMIT 10",
2ac4c8,2025-11-25 21:21:03.041704+00:00,3,14,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data correctly identifies the top 10 dealers with the highest 'no hit' percentage, meeting the application count filter. All key metrics, including total applications, no hit percentage, and approval percentage, align with the ground truth. The presence of an extra column is acceptable.",0.97,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END) AS approved_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS banking_no_hits,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS banking_no_hit_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  banking_no_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:21:27.259565+00:00,3,15,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data provided an incorrect list of the top 10 dealers. Only six dealers from the ground truth data were present in the candidate list, and their rankings were incorrect. Additionally, for the dealers that did appear in both sets, the associated metrics such as total applications, no banking hit percentage, and approval percentage were mostly inaccurate.",1.03,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS no_banking_hits,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_banking_hit_percentage,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END) AS approved_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '12' MONTH), MONTH)
  AND DATE(LastModifiedDate) < DATE_TRUNC(CURRENT_DATE, MONTH)
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  no_banking_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:21:45.542727+00:00,3,16,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data is completely incorrect. The list of dealers, the total application counts, and the calculated 'no banking hit percentage' and 'approval percentage' do not match the ground truth. The candidate appears to have incorrectly filtered for dealers with a 100% 'no banking hit' rate, rather than ranking by the highest percentages as requested.",0.97,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END) AS approved_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage,
  COUNT(
    CASE
      WHEN FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
      OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      THEN 1
    END
  ) AS banking_hits,
  (
    COUNT(*) - COUNT(
      CASE
        WHEN FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
        THEN 1
      END
    )
  ) AS no_banking_hits,
  ROUND(
    SAFE_DIVIDE(
      (
        COUNT(*) - COUNT(
          CASE
            WHEN FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
            THEN 1
          END
        )
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_banking_hit_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH)
  AND DATE(LastModifiedDate) < DATE_TRUNC(CURRENT_DATE, MONTH)
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  total_applications > 30
ORDER BY
  no_banking_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:22:05.116054+00:00,3,17,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data is completely incorrect. The list of dealers, the 'no banking hit percentage', and the 'approval percentage' values do not match the ground truth at all. The candidate data incorrectly shows all dealers with a 100% 'no banking hit percentage', which contradicts the ground truth data.",0.72,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(*) - COUNT(
        CASE
          WHEN FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
          OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_banking_hit_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  no_banking_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:22:30.782302+00:00,3,18,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data provides a different list of top 10 dealers. While a few dealer names overlap with the ground truth (e.g., 'MAHAVEER MOTORS 33091', 'SAYAN MOTORS HONDA'), the corresponding values for total applications, no banking hit percentage, and approval percentage are all incorrect.",1.16,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS no_banking_hit_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_banking_hit_percentage_pct,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  total_applications > 30
ORDER BY
  no_banking_hit_percentage_pct DESC
LIMIT 10",
2ac4c8,2025-11-25 21:22:49.074655+00:00,3,19,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data perfectly matches the ground truth data. All rows and corresponding values are identical, and the column name difference ('no_banking_hit_applications' vs 'no_banking_hit_count') is semantically equivalent and acceptable.",0.92,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS no_banking_hit_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS no_banking_hit_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  no_banking_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:23:14.650647+00:00,3,20,Show me the top 10 dealers where banking model has highest no hit percentage? application count should be greater than 30 and what is the approval percentage?,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data is correct. It provides the same top 10 dealers with identical values for all metrics as the ground truth. The slight reordering of two dealers with the exact same 'no banking hit percentage' is acceptable as no secondary sort order was specified.,0.84,0,0,"SELECT
  Dealer_Name_Supplier__c,
  COUNT(*) AS total_applications,
  COUNT(
    CASE
      WHEN NOT (
        FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
        OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
      )
      THEN 1
    END
  ) AS banking_no_hits,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        CASE
          WHEN NOT (
            FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKH%'
            OR FINAL_APPLICANT_SCORECARD_MODEL_BRE LIKE '%_BKR%'
          )
          THEN 1
        END
      ),
      COUNT(*)
    ) * 100,
    2
  ) AS banking_no_hit_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('ACCEPT', 'Sanction') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS approval_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
GROUP BY
  Dealer_Name_Supplier__c
HAVING
  COUNT(*) > 30
ORDER BY
  banking_no_hit_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:23:31.442951+00:00,4,1,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly provides the bounce rate for Assam, which matches the ground truth value of 21.61. While the candidate data has fewer columns, it directly and accurately answers the user's question.",0.71,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t1.STATE) AS state,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate AS m
WHERE
  t1.BUSINESS_DATE = m.max_business_date
  AND UPPER(t1.STATE) = 'ASSAM'
  AND t1.SOM_DPD = 0
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  t1.STATE",
2ac4c8,2025-11-25 21:23:45.002942+00:00,4,2,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data provides the correct values for total accounts, bounced accounts, and the bounce rate for the state of Assam, perfectly matching the ground truth data.",0.91,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t1.STATE) AS state,
  COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END) AS bounced_accounts_0_dpd,
  COUNT(DISTINCT t1.AGREEMENTNO) AS total_accounts_0_dpd,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxBusinessDate AS mbd
WHERE
  t1.BUSINESS_DATE = mbd.max_dt
  AND t1.SOM_DPD = 0
  AND UPPER(t1.STATE) = 'ASSAM'
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  t1.STATE
ORDER BY
  bounce_rate_0_dpd_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:23:58.916519+00:00,4,3,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the bounce rate as 21.61, which matches the ground truth. Although it lacks the contextual columns present in the ground truth, it directly and accurately answers the user's specific question.",0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Bounce_Flag = 'Y' THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd_for_assam
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
CROSS JOIN MaxDate AS T1
WHERE
  T2.BUSINESS_DATE = T1.max_business_date
  AND UPPER(T2.STATE) = 'ASSAM'
  AND T2.SOM_DPD = 0
  AND T2.SOM_NPASTAGEID = 'REGULAR'
  AND T2.SOM_POS > 0",
2ac4c8,2025-11-25 21:24:12.295644+00:00,4,4,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the bounce rate as 21.61, which matches the ground truth. Although it lacks the contextual columns present in the ground truth, it directly and accurately answers the user's specific question.",0.74,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Bounce_Flag = 'Y' THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd_for_assam
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
INNER JOIN MaxDate AS T1
  ON T2.BUSINESS_DATE = T1.max_business_date
WHERE
  T2.SOM_DPD = 0
  AND UPPER(T2.STATE) = 'ASSAM'
  AND T2.SOM_NPASTAGEID = 'REGULAR'
  AND T2.SOM_POS > 0",
2ac4c8,2025-11-25 21:24:27.906328+00:00,4,5,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data provides the correct values for total accounts, bounced accounts, and the bounce rate for Assam, perfectly matching the ground truth. The column names are different, but the data is semantically equivalent.",0.85,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END) AS bounced_accounts_0_dpd,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_accounts_0_dpd,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_dt
WHERE
  t.SOM_DPD = 0
  AND UPPER(t.STATE) = 'ASSAM'
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE",
2ac4c8,2025-11-25 21:24:41.470211+00:00,4,6,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the bounce rate as 21.61, which matches the ground truth. Although it lacks the contextual columns present in the ground truth, it directly and accurately answers the user's specific question.",0.75,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Bounce_Flag = 'Y' THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd_for_assam
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
INNER JOIN MaxDate AS M
  ON T2.BUSINESS_DATE = M.max_dt
WHERE
  T2.SOM_DPD = 0
  AND UPPER(T2.STATE) = 'ASSAM'
  AND T2.SOM_NPASTAGEID = 'REGULAR'
  AND T2.SOM_POS > 0",
2ac4c8,2025-11-25 21:24:58.336816+00:00,4,7,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate correctly identified the bounce rate for Assam as 21.61. Although it omits the underlying total and bounced account numbers present in the ground truth, it directly and accurately answers the user's specific question.",0.77,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS m
  ON t.BUSINESS_DATE = m.dt
WHERE
  UPPER(t.STATE) = 'ASSAM'
  AND t.SOM_DPD = 0
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  bounce_rate_0_dpd_percentage DESC
LIMIT 10",
2ac4c8,2025-11-25 21:25:12.306069+00:00,4,8,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data provides the correct values for total accounts, bounced accounts, and the final bounce rate for the state of Assam, matching the ground truth data exactly.",0.69,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(STATE) AS state_name,
  COUNT(DISTINCT CASE WHEN Bounce_Flag = 'Y' THEN AGREEMENTNO END) AS bounced_0_dpd_accounts,
  COUNT(DISTINCT AGREEMENTNO) AS total_0_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN Bounce_Flag = 'Y' THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND UPPER(STATE) = 'ASSAM'
  AND SOM_DPD = 0
  AND SOM_NPASTAGEID = 'REGULAR'
  AND SOM_POS > 0
GROUP BY
  state_name
ORDER BY
  state_name",
2ac4c8,2025-11-25 21:25:25.313398+00:00,4,9,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data perfectly matches the ground truth, providing the correct bounce rate, total accounts, and bounced accounts for Assam.",0.74,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t1.STATE) AS state,
  COUNT(DISTINCT t1.AGREEMENTNO) AS total_0_dpd_accounts,
  COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END) AS bounced_0_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate AS t2
WHERE
  t1.BUSINESS_DATE = t2.dt
  AND t1.SOM_DPD = 0
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
  AND UPPER(t1.STATE) = 'ASSAM'
GROUP BY
  1",
2ac4c8,2025-11-25 21:25:40.752235+00:00,4,10,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data provides the correct values for total accounts, bounced accounts, and the bounce rate for the state of Assam, perfectly matching the ground truth data.",0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t1.STATE) AS state,
  COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END) AS bounced_accounts_0_dpd,
  COUNT(DISTINCT t1.AGREEMENTNO) AS total_accounts_0_dpd,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate
WHERE
  t1.BUSINESS_DATE = MaxDate.max_dt
  AND UPPER(t1.STATE) = 'ASSAM'
  AND t1.SOM_DPD = 0
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:25:59.127104+00:00,4,11,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data correctly identifies the bounce rate value but fails to include the 'state' column. This is crucial context, as the user specifically asked for the rate for 'Assam'. Without this information, the answer is incomplete and ambiguous.",0.83,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN Bounce_Flag = 'Y' THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND SOM_DPD = 0
  AND UPPER(STATE) = 'ASSAM'
  AND SOM_NPASTAGEID = 'REGULAR'
  AND SOM_POS > 0",
2ac4c8,2025-11-25 21:26:13.895719+00:00,4,12,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly provides the requested bounce rate for Assam. While it omits the underlying total and bounced account numbers, it accurately answers the user's specific question.",0.73,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(STATE) AS state,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Bounce_Flag = 'Y' THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
INNER JOIN MaxDate AS md
  ON T2.BUSINESS_DATE = md.max_business_date
WHERE
  UPPER(T2.STATE) = 'ASSAM'
  AND T2.SOM_DPD = 0
  AND T2.SOM_NPASTAGEID = 'REGULAR'
  AND T2.SOM_POS > 0
GROUP BY
  UPPER(T2.STATE)",
2ac4c8,2025-11-25 21:26:29.283116+00:00,4,13,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly provides the bounce rate for Assam, which matches the ground truth value of 21.61. While the candidate data has fewer columns, it directly and accurately answers the user's question.",0.78,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t1.STATE) AS state,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
JOIN MaxBusinessDate AS t2
  ON t1.BUSINESS_DATE = t2.max_dt
WHERE
  UPPER(t1.STATE) = 'ASSAM'
  AND t1.SOM_DPD = 0
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  1",
2ac4c8,2025-11-25 21:26:44.106457+00:00,4,14,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly provides the requested bounce rate for Assam. While it omits the underlying total and bounced account numbers, it accurately answers the user's specific question.",0.89,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Bounce_Flag = 'Y' THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  UPPER(t.STATE) = 'ASSAM'
  AND t.SOM_DPD = 0
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  t.STATE",
2ac4c8,2025-11-25 21:27:02.672544+00:00,4,15,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data is missing the 'state' column, which is a critical piece of information requested by the user ('for Assam') and is present in the ground truth. While the numerical values are correct, the result is incomplete without this context.",0.7,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT CASE WHEN T2.Bounce_Flag = 'Y' THEN T2.AGREEMENTNO END) AS bounced_0_dpd_accounts,
  COUNT(DISTINCT T2.AGREEMENTNO) AS total_0_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Bounce_Flag = 'Y' THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_0_dpd
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
JOIN MaxBusinessDate AS M
  ON T2.BUSINESS_DATE = M.max_dt
WHERE
  T2.SOM_DPD = 0
  AND T2.SOM_NPASTAGEID = 'REGULAR'
  AND T2.SOM_POS > 0
  AND UPPER(T2.STATE) = 'ASSAM'",
2ac4c8,2025-11-25 21:27:17.768141+00:00,4,16,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate correctly identified the bounce rate for Assam as 21.61, which matches the ground truth. While the candidate data omits contextual columns like total and bounced accounts, it directly and accurately answers the user's specific question.",0.7,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Bounce_Flag = 'Y' THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_0_dpd_assam
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
INNER JOIN MaxDate AS md
  ON T2.BUSINESS_DATE = md.max_dt
WHERE
  T2.SOM_DPD = 0
  AND UPPER(T2.STATE) = 'ASSAM'
  AND T2.SOM_NPASTAGEID = 'REGULAR'
  AND T2.SOM_POS > 0",
2ac4c8,2025-11-25 21:27:32.972938+00:00,4,17,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data provides the correct values for total accounts, bounced accounts, and the bounce rate for the state of Assam, perfectly matching the ground truth data.",0.66,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(t1.STATE) AS state,
  COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END) AS bounced_accounts_0_dpd,
  COUNT(DISTINCT t1.AGREEMENTNO) AS total_accounts_0_dpd,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.Bounce_Flag = 'Y' THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate
WHERE
  t1.BUSINESS_DATE = MaxDate.max_dt
  AND UPPER(t1.STATE) = 'ASSAM'
  AND t1.SOM_DPD = 0
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  1
ORDER BY
  bounce_rate_0_dpd_percentage DESC",
2ac4c8,2025-11-25 21:27:46.025191+00:00,4,18,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. All rows and corresponding values are identical, even though one column name is slightly different, which is acceptable.",0.93,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(STATE) AS state,
  COUNT(DISTINCT AGREEMENTNO) AS total_0_dpd_accounts_in_state,
  COUNT(DISTINCT CASE WHEN Bounce_Flag = 'Y' THEN AGREEMENTNO END) AS bounced_0_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN Bounce_Flag = 'Y' THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND SOM_DPD = 0
  AND UPPER(STATE) = 'ASSAM'
  AND SOM_NPASTAGEID = 'REGULAR'
  AND SOM_POS > 0
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:28:00.994816+00:00,4,19,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data is a perfect match to the ground truth. The difference in capitalization for the state name ('ASSAM' vs 'Assam') is semantically irrelevant.,0.83,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  'Assam' AS state,
  COUNT(DISTINCT T2.AGREEMENTNO) AS total_0_dpd_accounts,
  COUNT(DISTINCT CASE WHEN T2.Bounce_Flag = 'Y' THEN T2.AGREEMENTNO END) AS bounced_0_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Bounce_Flag = 'Y' THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
CROSS JOIN MaxDate
WHERE
  T2.BUSINESS_DATE = MaxDate.max_business_date
  AND UPPER(T2.STATE) = 'ASSAM'
  AND T2.SOM_DPD = 0
  AND T2.SOM_NPASTAGEID = 'REGULAR'
  AND T2.SOM_POS > 0",
2ac4c8,2025-11-25 21:28:18.438080+00:00,4,20,SHow me the bounce rate on 0 dpd for Assam?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data correctly provides the bounce rate value but omits the 'state' column. The user explicitly asked for the rate for 'Assam', so the state should be included in the result to provide context for the metric.",0.67,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Bounce_Flag = 'Y' THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS bounce_rate_on_0_dpd
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
CROSS JOIN MaxDate AS T1
WHERE
  T2.BUSINESS_DATE = T1.max_dt
  AND T2.SOM_DPD = 0
  AND UPPER(T2.STATE) = 'ASSAM'
  AND T2.SOM_NPASTAGEID = 'REGULAR'
  AND T2.SOM_POS > 0",
2ac4c8,2025-11-25 21:28:26.198060+00:00,5,1,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.COLLECTIONS,ERROR,Error: 400 Syntax error: Unexpected i,0.37,0,0,"I apologize, but I cannot fulfill this request. The available schema for `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` does not contain any fields related to ""CIBIL score"" or ""rejection status"". Therefore, I am unable to query for rejections based on CIBIL score.","400 Syntax error: Unexpected identifier ""I"" at [1:1]; reason: invalidQuery, location: query, message: Syntax error: Unexpected identifier ""I"" at [1:1]

Location: US
Job ID: b896584c-85a0-403d-9f2d-da959e95394f
"
2ac4c8,2025-11-25 21:28:45.950143+00:00,5,2,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data correctly provides all the information present in the ground truth for the requested months. The inclusion of an extra month is acceptable per the evaluation rules.,0.95,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications_below_650,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_below_650,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:28:51.246693+00:00,5,3,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.COLLECTIONS,ERROR,Error: 400 Syntax error: Unexpected i,0.33,0,0,"I am sorry, but I cannot fulfill this request. The available schema for `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` does not contain information about ""CIBIL score"" or ""rejection reasons"". This table focuses on collections, delinquency, and loan performance metrics for existing accounts, not application-level rejection data based on credit scores.","400 Syntax error: Unexpected identifier ""I"" at [1:1]; reason: invalidQuery, location: query, message: Syntax error: Unexpected identifier ""I"" at [1:1]

Location: US
Job ID: 8e9932bd-d0eb-46ca-b8aa-c51ddea66ae7
"
2ac4c8,2025-11-25 21:29:14.786883+00:00,5,4,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data correctly matches the ground truth for the requested months (August, September, October). The presence of an additional month (July) is acceptable under the evaluation rules.",1.19,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_below_650,
  COUNT(*) AS total_applications_with_cibil_below_650,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND NOT SAFE_CAST(CIBIL_SCORE AS INT64) IS NULL
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:29:36.645947+00:00,5,5,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data correctly provides all the data points present in the ground truth for the requested months (August, September, October). The inclusion of an extra month (July) is acceptable as per the evaluation criteria.",1.02,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications_below_650_cibil,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_below_650_cibil,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND SAFE_CAST(CIBIL_SCORE AS BIGNUMERIC) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:29:42.752027+00:00,5,6,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.COLLECTIONS,ERROR,Error: 400 Syntax error: Unexpected i,0.34,0,0,"I cannot fulfill this request. The available schema for `TW_COLL_MART_HIST_v2` does not contain any information related to ""CIBIL score"" or ""rejection reasons"". This table focuses on post-disbursal collections, delinquency, and loan performance data.","400 Syntax error: Unexpected identifier ""I"" at [1:1]; reason: invalidQuery, location: query, message: Syntax error: Unexpected identifier ""I"" at [1:1]

Location: US
Job ID: e98c8631-f916-4b55-be5e-d738f40b37b7
"
2ac4c8,2025-11-25 21:30:02.035821+00:00,5,7,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data is a perfect match to the ground truth. It contains the same number of rows and identical values for each corresponding month, although the row order is different, which is acceptable.",1.18,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications_cibil_lt_650,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_cibil_lt_650,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '3' MONTH), MONTH)
  AND DATE(LastModifiedDate) < DATE_TRUNC(CURRENT_DATE, MONTH)
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:30:25.322641+00:00,5,8,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data is a perfect match to the ground truth data. Although the row order is different, the values for each month are identical, which is acceptable as no specific sorting was requested.",1.09,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications_below_650_cibil,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_below_650_cibil,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '2' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:30:45.916912+00:00,5,9,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data correctly provides all the metrics for the three months specified in the ground truth. The inclusion of an additional month (July 2025) is acceptable as per the evaluation criteria.,1.17,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications_below_650,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_below_650,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND NOT SAFE_CAST(CIBIL_SCORE AS INT64) IS NULL
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:31:10.783742+00:00,5,10,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data is a perfect match to the ground truth. All rows and corresponding data points are identical, despite differences in column names and row sorting, which are permissible.",1.1,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNTIF(SAFE_CAST(CIBIL_SCORE AS INT64) < 650) AS total_applications_cibil_lt_650,
  COUNTIF(
    SAFE_CAST(CIBIL_SCORE AS INT64) < 650
    AND BRE_Sanction_Result__c IN ('REJECT', 'Reject')
  ) AS rejected_applications_cibil_lt_650,
  ROUND(
    SAFE_DIVIDE(
      COUNTIF(
        SAFE_CAST(CIBIL_SCORE AS INT64) < 650
        AND BRE_Sanction_Result__c IN ('REJECT', 'Reject')
      ),
      COUNTIF(SAFE_CAST(CIBIL_SCORE AS INT64) < 650)
    ) * 100,
    2
  ) AS rejection_rate_pct_cibil_lt_650
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '3' MONTH), MONTH)
  AND DATE(LastModifiedDate) < DATE_TRUNC(CURRENT_DATE, MONTH)
  AND NOT CIBIL_SCORE IS NULL /* Ensure CIBIL_SCORE is not null before casting */
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:31:16.899557+00:00,5,11,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.COLLECTIONS,ERROR,Error: 400 Syntax error: Unexpected i,0.35,0,0,"I am sorry, but I cannot fulfill this request as the provided table schema does not contain information about CIBIL scores or rejection reasons. The available data focuses on existing loan performance and collections metrics.","400 Syntax error: Unexpected identifier ""I"" at [1:1]; reason: invalidQuery, location: query, message: Syntax error: Unexpected identifier ""I"" at [1:1]

Location: US
Job ID: 79e6cdc7-2f80-488b-adee-8c32a01fbaea
"
2ac4c8,2025-11-25 21:31:36.890017+00:00,5,12,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data correctly provides all the metrics for the three months specified in the ground truth. The inclusion of an extra month (July 2025) is acceptable as per the evaluation criteria.,0.98,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications_cibil_lt_650,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_cibil_lt_650,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct_cibil_lt_650
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:31:58.796336+00:00,5,13,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data correctly provides all the data present in the ground truth for the requested three months. The inclusion of an extra month's data is acceptable as per the evaluation criteria.,1.14,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications_cibil_below_650,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_cibil_below_650,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:32:20.337975+00:00,5,14,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data is a perfect match to the ground truth. All rows and corresponding values are identical, although the sort order is different, which is permissible.",1.45,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications_cibil_below_650,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_cibil_below_650,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_cibil_below_650_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '2' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:32:39.273933+00:00,5,15,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data is a perfect match to the ground truth data. Although the row order is different, the values for each month are identical, which is acceptable as no specific ordering was requested.",1.24,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNTIF(SAFE_CAST(CIBIL_SCORE AS INT64) < 650) AS total_applications_below_650_cibil,
  COUNTIF(
    BRE_Sanction_Result__c IN ('REJECT', 'Reject')
    AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
  ) AS rejected_applications_below_650_cibil,
  ROUND(
    SAFE_DIVIDE(
      COUNTIF(
        BRE_Sanction_Result__c IN ('REJECT', 'Reject')
        AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
      ),
      COUNTIF(SAFE_CAST(CIBIL_SCORE AS INT64) < 650)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '2' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND NOT CIBIL_SCORE IS NULL /* Ensure CIBIL_SCORE is not null before casting */
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:32:45.576805+00:00,5,16,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.COLLECTIONS,ERROR,Error: 400 Syntax error: Unexpected i,0.4,0,0,"I am sorry, but I cannot fulfill this request. The available schema for `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` does not contain information about ""CIBIL score"" or ""rejection reasons"". This table focuses on collections, delinquency, and performance of disbursed loans.","400 Syntax error: Unexpected identifier ""I"" at [1:1]; reason: invalidQuery, location: query, message: Syntax error: Unexpected identifier ""I"" at [1:1]

Location: US
Job ID: 64b4c083-e79f-4951-b7dd-c3ef5af64e01
"
2ac4c8,2025-11-25 21:33:07.488241+00:00,5,17,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data correctly provides all the data present in the ground truth for the requested three months. The inclusion of an extra month's data is acceptable as per the evaluation criteria.,1.24,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications_cibil_below_650,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_cibil_below_650,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND NOT CIBIL_SCORE IS NULL
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:33:25.592312+00:00,5,18,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data correctly provides all the data points present in the ground truth for the months of August, September, and October. The inclusion of an extra month (July) is acceptable as per the evaluation criteria.",1.05,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '3' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND NOT CIBIL_SCORE IS NULL
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:33:42.900731+00:00,5,19,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data is a perfect match to the ground truth. Although the row order is different, the data points for each month are identical, which is acceptable as no specific sorting was requested.",1.14,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications_below_650_cibil,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_below_650_cibil,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH), MONTH), INTERVAL '2' MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:34:07.376056+00:00,5,20,What is the rejection based on CIBIL score below 650 in the last 3 months? Month on month?,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data provides the correct values for all requested metrics (total applications, rejected applications, and rejection rate) for each of the three months. The data is identical to the ground truth, only differing in the sort order of the months, which is acceptable.",1.6,0,0,"SELECT
  FORMAT_DATE('%Y-%m', DATE_TRUNC(DATE(LastModifiedDate), MONTH)) AS month,
  COUNT(*) AS total_applications_cibil_below_650,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_cibil_below_650,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= DATE_TRUNC(DATE_SUB(CURRENT_DATE, INTERVAL '3' MONTH), MONTH)
  AND DATE(LastModifiedDate) <= LAST_DAY(DATE_SUB(CURRENT_DATE, INTERVAL '1' MONTH))
  AND SAFE_CAST(CIBIL_SCORE AS INT64) < 650
GROUP BY
  1
ORDER BY
  1",
2ac4c8,2025-11-25 21:34:43.228949+00:00,6,1,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data correctly identifies the overall rejection rate (95.42%) and provides an accurate breakdown of rejection reasons with matching counts for all reasons present in the ground truth. The candidate provides extra, helpful columns and rows (e.g., total applications per reason) which add more context without contradicting the ground truth.",0.86,0,0,"SELECT
  COALESCE(t1.SCORECARD_MODEL_DESCRIPTION_BRE__c, 'Overall/Missing Reason') AS rejection_analysis_segment,
  COUNT(*) AS total_applications_in_segment,
  COUNT(CASE WHEN t1.BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_in_segment,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN t1.BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25` AS t1
WHERE
  DATE(t1.LastModifiedDate) >= '2025-10-01'
  AND DATE(t1.LastModifiedDate) < '2025-11-01'
  AND SAFE_CAST(t1.CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
GROUP BY
  ROLLUP (
    t1.SCORECARD_MODEL_DESCRIPTION_BRE__c
  )
ORDER BY
  CASE WHEN t1.SCORECARD_MODEL_DESCRIPTION_BRE__c IS NULL THEN 0 ELSE 1 END, /* Puts the overall aggregate row first */
  rejected_applications_in_segment DESC /* Sorts individual reasons by their rejection count */",
2ac4c8,2025-11-25 21:35:15.231597+00:00,6,2,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data correctly identifies the overall rejection rate (95.42%) and provides an accurate breakdown of all rejection reasons and their respective counts. The structural difference in presenting the data is acceptable as all core information requested by the user is present and correct.,0.94,0,0,"WITH SegmentStats AS (
  SELECT
    COUNT(*) AS total_applications_in_segment,
    COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS total_rejected_applications_in_segment,
    ROUND(
      SAFE_DIVIDE(
        COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
        COUNT(*)
      ) * 100,
      2
    ) AS overall_rejection_rate_in_segment_pct
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
)
SELECT
  t.SCORECARD_MODEL_DESCRIPTION_BRE__c AS rejection_reason,
  COUNT(*) AS rejected_count_for_this_reason,
  ROUND(SAFE_DIVIDE(COUNT(*), s.total_applications_in_segment) * 100, 2) AS rejection_rate_for_this_reason_pct,
  s.overall_rejection_rate_in_segment_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25` AS t
CROSS JOIN SegmentStats AS s
WHERE
  DATE(t.LastModifiedDate) >= '2025-10-01'
  AND DATE(t.LastModifiedDate) < '2025-11-01'
  AND SAFE_CAST(t.CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
  AND t.BRE_Sanction_Result__c IN ('REJECT', 'Reject')
GROUP BY
  rejection_reason,
  s.total_applications_in_segment,
  s.overall_rejection_rate_in_segment_pct
ORDER BY
  rejected_count_for_this_reason DESC",
2ac4c8,2025-11-25 21:35:35.017081+00:00,6,3,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,FAIL,"LLM: The AI agent correctly provided the overall summary of the rejection rate, total applications, and rejected applications. However, it completely failed to provide the breakdown of rejection reasons, which was a specific part of the user's question. The ground truth data contains multiple rows detailing the reasons for rejection, which are missing from the candidate's response.",0.71,0,0,"SELECT
  COUNT(*) AS total_applications,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= '2025-10-01'
  AND DATE(LastModifiedDate) < '2025-11-01'
  AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650",
2ac4c8,2025-11-25 21:35:51.950079+00:00,6,4,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,ERROR,Error: 400 Unrecognized name: reason_,0.58,0,0,"WITH FilteredApplications AS (
  SELECT
    BRE_Sanction_Result__c,
    SCORECARD_MODEL_DESCRIPTION_BRE__c
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
)
SELECT
  COUNT(*) AS total_applications,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct,
  (
    SELECT
      ARRAY_AGG(
        STRUCT(
          COALESCE(t.SCORECARD_MODEL_DESCRIPTION_BRE__c, 'NOT_SPECIFIED') AS rejection_reason_description,
          COUNT(*) AS reason_count
        ) ORDER BY reason_count DESC, rejection_reason_description ASC
      )
    FROM FilteredApplications AS t
    WHERE
      t.BRE_Sanction_Result__c IN ('REJECT', 'Reject')
    GROUP BY
      t.SCORECARD_MODEL_DESCRIPTION_BRE__c
  ) AS rejection_reasons_breakdown
FROM FilteredApplications","400 Unrecognized name: reason_count at [27:20]; reason: invalidQuery, location: query, message: Unrecognized name: reason_count at [27:20]

Location: asia-south1
Job ID: 8215bb59-1aa2-4250-b7d5-155d3cade64b
"
2ac4c8,2025-11-25 21:36:38.067126+00:00,6,5,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data correctly identifies the overall rejection rate of 95.42% and provides an accurate breakdown of all rejection reasons and their corresponding counts, which aligns perfectly with the ground truth. The candidate includes extra rows with zero rejections and additional columns, but this constitutes supplementary information and does not contradict the core data requested by the user.",0.71,0,0,"SELECT
  COALESCE(t2.rejection_description_bre, 'N/A') AS rejection_description_bre,
  COALESCE(t2.final_scorecard_model_bre, 'N/A') AS final_scorecard_model_bre,
  t2.applications_in_segment_for_reason,
  t2.rejected_applications_for_reason,
  ROUND(
    SAFE_DIVIDE(t2.rejected_applications_for_reason, t2.applications_in_segment_for_reason) * 100,
    2
  ) AS rejection_rate_for_reason_pct,
  ROUND(
    SAFE_DIVIDE(t1.total_rejected_applications_in_segment, t1.total_applications_in_segment) * 100,
    2
  ) AS overall_rejection_rate_in_segment_pct
FROM (
  SELECT
    COUNT(*) AS total_applications_in_segment,
    COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS total_rejected_applications_in_segment
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
) AS t1
CROSS JOIN (
  SELECT
    SCORECARD_MODEL_DESCRIPTION_BRE__c AS rejection_description_bre,
    FINAL_APPLICANT_SCORECARD_MODEL_BRE AS final_scorecard_model_bre,
    COUNT(*) AS applications_in_segment_for_reason,
    COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_for_reason
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
  GROUP BY
    1,
    2
) AS t2
ORDER BY
  t2.rejected_applications_for_reason DESC",
2ac4c8,2025-11-25 21:37:06.908769+00:00,6,6,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data successfully provides both the overall rejection rate and the detailed breakdown of rejection reasons with their corresponding counts. All numerical values and reason descriptions are a direct match with the ground truth. The structural differences in table layout are acceptable as the core data is present and accurate.,1.18,0,0,"SELECT
  'Overall Rejection Rate' AS category,
  NULL AS rejection_reason,
  COUNT(*) AS total_applications,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= '2025-10-01'
  AND DATE(LastModifiedDate) < '2025-11-01'
  AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
UNION ALL
SELECT
  'Rejection Reason Breakdown' AS category,
  COALESCE(SCORECARD_MODEL_DESCRIPTION_BRE__c, 'Unknown/Missing Reason') AS rejection_reason,
  NULL AS total_applications,
  COUNT(*) AS rejected_applications,
  NULL AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= '2025-10-01'
  AND DATE(LastModifiedDate) < '2025-11-01'
  AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
  AND BRE_Sanction_Result__c IN ('REJECT', 'Reject')
GROUP BY
  2
ORDER BY
  category DESC,
  rejected_applications DESC",
2ac4c8,2025-11-25 21:37:33.707591+00:00,6,7,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,ERROR,Error: 400 Function not found: PARSE_,0.52,0,0,"WITH FilteredApplications AS (
  SELECT
    BRE_Sanction_Result__c,
    SCORECARD_MODEL_DESCRIPTION_BRE__c,
    CIBIL_SCORE
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE.PARSE_INT64(CIBIL_SCORE) BETWEEN 300 AND 650
)
SELECT
  'Overall Rejection Metrics' AS category,
  NULL AS rejection_reason_description,
  COUNT(*) AS total_applications_in_segment,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS total_rejected_applications_in_segment,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS overall_rejection_rate_pct
FROM FilteredApplications
UNION ALL
SELECT
  'Rejection Reason Breakdown' AS category,
  COALESCE(SCORECARD_MODEL_DESCRIPTION_BRE__c, 'Unknown/Missing Description') AS rejection_reason_description,
  NULL AS total_applications_in_segment, /* Not applicable for breakdown rows */
  COUNT(*) AS total_rejected_applications_in_segment,
  NULL AS overall_rejection_rate_pct /* Not applicable for breakdown rows */
FROM FilteredApplications
WHERE
  BRE_Sanction_Result__c IN ('REJECT', 'Reject')
GROUP BY
  rejection_reason_description
ORDER BY
  category,
  total_rejected_applications_in_segment DESC","400 Function not found: PARSE_INT64 at [10:9]; reason: invalidQuery, location: query, message: Function not found: PARSE_INT64 at [10:9]

Location: asia-south1
Job ID: b42a3188-42f1-4410-92a8-4d4e2858e059
"
2ac4c8,2025-11-25 21:37:51.467045+00:00,6,8,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data correctly calculated the overall rejection rate but failed to provide the requested breakdown of rejection reasons. The ground truth data includes a detailed list of reasons, which is a key part of the user's question and is completely missing from the candidate's response.",0.83,0,0,"SELECT
  COUNT(*) AS total_applications_in_range,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= '2025-10-01'
  AND DATE(LastModifiedDate) < '2025-11-01'
  AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650",
2ac4c8,2025-11-25 21:38:24.927761+00:00,6,9,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data correctly identifies the overall rejection rate and provides an accurate breakdown of all rejection reasons and their respective counts. The term 'Undefined Reason' is semantically equivalent to the ground truth's 'Unknown Reason'.,0.8,0,0,"WITH FilteredApplications AS (
  SELECT
    BRE_Sanction_Result__c,
    SCORECARD_MODEL_DESCRIPTION_BRE__c,
    COUNT(*) OVER () AS total_filtered_applications,
    COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) OVER () AS total_rejected_applications
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
)
SELECT
  ROUND(
    SAFE_DIVIDE(MAX(total_rejected_applications), MAX(total_filtered_applications)) * 100,
    2
  ) AS overall_rejection_rate_pct,
  COALESCE(SCORECARD_MODEL_DESCRIPTION_BRE__c, 'Undefined Reason') AS rejection_reason,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS count_of_rejections_for_this_reason
FROM FilteredApplications
WHERE
  BRE_Sanction_Result__c IN ('REJECT', 'Reject')
GROUP BY
  rejection_reason
ORDER BY
  count_of_rejections_for_this_reason DESC",
2ac4c8,2025-11-25 21:38:54.231902+00:00,6,10,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data correctly identifies the overall rejection rate and provides an accurate breakdown of all rejection reasons and their respective counts. The reason 'Undefined Scorecard Model Description' is considered semantically equivalent to 'Unknown Reason' as they both represent the same large cohort of 5250 rejections.,0.92,0,0,"WITH FilteredApplications AS (
  SELECT
    BRE_Sanction_Result__c,
    SCORECARD_MODEL_DESCRIPTION_BRE__c,
    SAFE_CAST(CIBIL_SCORE AS INT64) AS cibil_score_int
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND NOT SAFE_CAST(CIBIL_SCORE AS INT64) IS NULL
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
), OverallRejectionSummary AS (
  SELECT
    COUNT(*) AS total_applications,
    COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications,
    ROUND(
      SAFE_DIVIDE(
        COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
        COUNT(*)
      ) * 100,
      2
    ) AS overall_rejection_rate_pct
  FROM FilteredApplications
)
SELECT
  (
    SELECT
      overall_rejection_rate_pct
    FROM OverallRejectionSummary
  ) AS overall_rejection_rate_for_segment_pct,
  COALESCE(t1.SCORECARD_MODEL_DESCRIPTION_BRE__c, 'Undefined Scorecard Model Description') AS rejection_reason_description,
  COUNT(t1.BRE_Sanction_Result__c) AS count_of_rejections_by_reason
FROM FilteredApplications AS t1
WHERE
  t1.BRE_Sanction_Result__c IN ('REJECT', 'Reject')
GROUP BY
  rejection_reason_description
ORDER BY
  count_of_rejections_by_reason DESC",
2ac4c8,2025-11-25 21:39:20.241820+00:00,6,11,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data is incomplete. While it correctly identifies the overall rejection rate and some specific rejection reasons, it fails to include the most frequent reason, 'Unknown Reason', which accounts for 5250 rejected applications.",0.96,0,0,"WITH FilteredApplications AS (
  SELECT
    BRE_Sanction_Result__c,
    SCORECARD_MODEL_DESCRIPTION_BRE__c
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
), OverallStats AS (
  SELECT
    COUNT(*) AS total_applications,
    COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications
  FROM FilteredApplications
), RejectionReasons AS (
  SELECT
    SCORECARD_MODEL_DESCRIPTION_BRE__c AS rejection_reason,
    COUNT(*) AS reason_count
  FROM FilteredApplications
  WHERE
    BRE_Sanction_Result__c IN ('REJECT', 'Reject')
    AND NOT SCORECARD_MODEL_DESCRIPTION_BRE__c IS NULL
  GROUP BY
    rejection_reason
)
SELECT
  (
    SELECT
      ROUND(SAFE_DIVIDE(rejected_applications, total_applications) * 100, 2)
    FROM OverallStats
  ) AS overall_rejection_rate_pct,
  reasons.rejection_reason,
  reasons.reason_count
FROM RejectionReasons AS reasons
ORDER BY
  reasons.reason_count DESC",
2ac4c8,2025-11-25 21:39:40.068408+00:00,6,12,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,ERROR,Error: 400 Unrecognized name: rejecte,0.49,0,0,"WITH CohortApplications AS (
  SELECT
    BRE_Sanction_Result__c,
    SCORECARD_MODEL_DESCRIPTION_BRE__c
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS overall_rejection_rate_pct, /* Overall Rejection Rate for the defined cohort */
  (
    SELECT
      ARRAY_AGG(
        STRUCT(
          COALESCE(SCORECARD_MODEL_DESCRIPTION_BRE__c, 'Unknown Reason') AS rejection_reason,
          COUNT(*) AS rejected_count
        ) ORDER BY rejected_count DESC, rejection_reason ASC
        LIMIT 10
      )
    FROM CohortApplications
    WHERE
      BRE_Sanction_Result__c IN ('REJECT', 'Reject')
    GROUP BY
      SCORECARD_MODEL_DESCRIPTION_BRE__c
  ) AS top_rejection_reasons_breakdown /* Breakdown of Top 10 Rejection Reasons for the rejected cases within the cohort */
FROM CohortApplications
LIMIT 1","400 Unrecognized name: rejected_count at [25:20]; reason: invalidQuery, location: query, message: Unrecognized name: rejected_count at [25:20]

Location: asia-south1
Job ID: 49fc6e83-85be-46ed-8cd2-f36f023c3b91
"
2ac4c8,2025-11-25 21:40:06.411329+00:00,6,13,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,ERROR,Error: 400 SELECT list expression ref,0.56,0,0,"WITH FilteredApplications AS (
  SELECT
    CIBIL_SCORE,
    BRE_Sanction_Result__c,
    SCORECARD_MODEL_DESCRIPTION_BRE__c
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS BIGNUMERIC) BETWEEN 300 AND 650
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN fa.BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) OVER () /* Total rejected applications in the segment */,
      COUNT(*) OVER () /* Total applications in the segment */
    ) * 100,
    2
  ) AS overall_rejection_rate_pct, /* Overall rejection rate for the specified segment (CIBIL 300-650 in October 2025) */
  COALESCE(fa.SCORECARD_MODEL_DESCRIPTION_BRE__c, 'Unspecified Reason') AS rejection_reason, /* Breakdown of rejection reasons for applications within this segment */
  COUNT(*) AS rejected_count_by_reason,
  ROUND(
    SAFE_DIVIDE(
      COUNT(*),
      COUNT(CASE WHEN fa.BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) OVER ()
    ) * 100,
    2
  ) AS percent_of_total_rejections_by_reason /* Percentage of total rejections (within this segment) attributed to this reason */
FROM FilteredApplications AS fa
WHERE
  fa.BRE_Sanction_Result__c IN ('REJECT', 'Reject') /* Only focus on rejected applications for the reason breakdown */
GROUP BY
  rejection_reason
ORDER BY
  rejected_count_by_reason DESC","400 SELECT list expression references fa.BRE_Sanction_Result__c which is neither grouped nor aggregated at [15:23]; reason: invalidQuery, location: query, message: SELECT list expression references fa.BRE_Sanction_Result__c which is neither grouped nor aggregated at [15:23]

Location: asia-south1
Job ID: 06e6f09d-b219-44cb-969f-b8e843ea01c4
"
2ac4c8,2025-11-25 21:40:34.313005+00:00,6,14,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data correctly identifies the overall rejection rate and the counts for each rejection reason. However, it fails to provide the reason description 'Unknown Reason' for the largest group of 5250 rejected applications, leaving the description field blank for that row.",0.84,0,0,"SELECT
  (
    SELECT
      ROUND(
        SAFE_DIVIDE(
          COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
          COUNT(*)
        ) * 100,
        2
      )
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
    WHERE
      DATE(LastModifiedDate) >= '2025-10-01'
      AND DATE(LastModifiedDate) < '2025-11-01'
      AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
  ) AS overall_rejection_rate_pct_for_criteria,
  SCORECARD_MODEL_DESCRIPTION_BRE__c AS rejection_reason_description,
  COUNT(*) AS rejected_applications_count
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= '2025-10-01'
  AND DATE(LastModifiedDate) < '2025-11-01'
  AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
  AND BRE_Sanction_Result__c IN ('REJECT', 'Reject')
GROUP BY
  2
ORDER BY
  rejected_applications_count DESC",
2ac4c8,2025-11-25 21:41:05.723543+00:00,6,15,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,PASS,LLM: The candidate data successfully provides the two key pieces of information requested by the user: the overall rejection rate (95.42%) and a detailed breakdown of rejection reasons with their corresponding counts. All numerical values and reason descriptions match the ground truth.,1.05,0,0,"WITH MonthlyCIBILCohort AS (
  SELECT
    BRE_Sanction_Result__c,
    SCORECARD_MODEL_DESCRIPTION_BRE__c
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
)
SELECT
  'Overall Rejection Rate (%)' AS metric_type,
  NULL AS rejection_reason,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS percentage_value,
  NULL AS rejected_count_for_reason
FROM MonthlyCIBILCohort
UNION ALL
SELECT
  'Rejection Reason Breakdown' AS metric_type,
  COALESCE(SCORECARD_MODEL_DESCRIPTION_BRE__c, 'UNKNOWN/NOT_SPECIFIED') AS rejection_reason,
  NULL AS percentage_value,
  COUNT(*) AS rejected_count_for_reason
FROM MonthlyCIBILCohort
WHERE
  BRE_Sanction_Result__c IN ('REJECT', 'Reject')
GROUP BY
  2
ORDER BY
  metric_type DESC,
  rejected_count_for_reason DESC",
2ac4c8,2025-11-25 21:41:34.400682+00:00,6,16,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data correctly provides the overall rejection rate of 95.42% and accurately lists all the rejection reasons with their corresponding counts. Although the data is structured differently from the ground truth (repeating the overall rate on each row instead of a separate summary row), it contains all the correct information requested by the user.",0.8,0,0,"SELECT
  t2.rejection_reason,
  t2.rejected_count_for_reason,
  t1.overall_rejection_rate_pct
FROM (
  SELECT
    COUNT(*) AS total_applications,
    COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications,
    ROUND(
      SAFE_DIVIDE(
        COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
        COUNT(*)
      ) * 100,
      2
    ) AS overall_rejection_rate_pct
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
) AS t1
CROSS JOIN (
  SELECT
    COALESCE(SCORECARD_MODEL_DESCRIPTION_BRE__c, 'UNKNOWN_REASON') AS rejection_reason,
    COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_count_for_reason
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
    AND BRE_Sanction_Result__c IN ('REJECT', 'Reject')
  GROUP BY
    rejection_reason
) AS t2
ORDER BY
  t2.rejected_count_for_reason DESC",
2ac4c8,2025-11-25 21:42:03.198697+00:00,6,17,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data correctly provides the overall summary of total applications, rejected applications, and the rejection rate. However, it completely omits the breakdown of rejection reasons, which was a specific part of the user's question. The ground truth data includes a detailed list of these reasons, which is missing from the candidate's response.",0.73,0,0,"SELECT
  COUNT(*) AS total_applications,
  COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END) AS rejected_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= '2025-10-01'
  AND DATE(LastModifiedDate) < '2025-11-01'
  AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650",
2ac4c8,2025-11-25 21:42:29.971894+00:00,6,18,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data correctly calculated the overall rejection rate and total counts. However, it failed to provide the detailed breakdown of rejection reasons as requested by the user and present in the ground truth data. It only provided aggregated counts of the reasons.",0.95,0,0,"SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN t.BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS overall_rejection_rate_pct,
  COUNT(CASE WHEN t.BRE_Sanction_Result__c = 'REJECT' THEN 1 END) AS rejected_count_uppercase_reason,
  COUNT(CASE WHEN t.BRE_Sanction_Result__c = 'Reject' THEN 1 END) AS rejected_count_lowercase_reason,
  COUNT(*) AS total_applications_in_segment
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25` AS t
WHERE
  DATE(t.LastModifiedDate) >= '2025-10-01'
  AND DATE(t.LastModifiedDate) < '2025-11-01'
  AND SAFE_CAST(t.CIBIL_SCORE AS INT64) BETWEEN 300 AND 650",
2ac4c8,2025-11-25 21:43:00.914286+00:00,6,19,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,FAIL,"LLM: The candidate data correctly identifies the overall rejection rate and the counts for each rejection reason. However, it fails to provide the reason text for the largest category of rejections (5250 cases), which the ground truth labels as 'Unknown Reason'. The candidate data shows a null/empty value for this reason, which is a significant omission.",0.93,0,0,"WITH FilteredApplications AS (
  SELECT
    BRE_Sanction_Result__c,
    SCORECARD_MODEL_DESCRIPTION_BRE__c
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
  WHERE
    DATE(LastModifiedDate) >= '2025-10-01'
    AND DATE(LastModifiedDate) < '2025-11-01'
    AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
), OverallRejectionMetrics AS (
  SELECT
    ROUND(
      SAFE_DIVIDE(
        COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
        COUNT(*)
      ) * 100,
      2
    ) AS overall_rejection_rate_pct
  FROM FilteredApplications
), RejectedReasonsBreakdown AS (
  SELECT
    SCORECARD_MODEL_DESCRIPTION_BRE__c AS rejection_reason_description,
    COUNT(*) AS rejected_count
  FROM FilteredApplications
  WHERE
    BRE_Sanction_Result__c IN ('REJECT', 'Reject')
  GROUP BY
    1
)
SELECT
  orm.overall_rejection_rate_pct,
  rr.rejection_reason_description,
  rr.rejected_count
FROM OverallRejectionMetrics AS orm
CROSS JOIN RejectedReasonsBreakdown AS rr
ORDER BY
  rr.rejected_count DESC",
2ac4c8,2025-11-25 21:43:27.031338+00:00,6,20,What is the rejection rate for applications where CIBIL score is between 300-650 in October 2025? Also list out the reason of rejections for these cases.,Sourcing,DomainType.SOURCING,PASS,"LLM: The candidate data successfully provides the correct overall rejection rate and an accurate breakdown of rejection reasons with their corresponding counts, fully answering the user's question.",0.82,0,0,"SELECT
  'Overall Rejection Rate' AS metric,
  CAST(NULL AS STRING) AS rejection_reason,
  CAST(NULL AS INT64) AS count_of_applications,
  ROUND(
    SAFE_DIVIDE(
      COUNT(CASE WHEN BRE_Sanction_Result__c IN ('REJECT', 'Reject') THEN 1 END),
      COUNT(*)
    ) * 100,
    2
  ) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= '2025-10-01'
  AND DATE(LastModifiedDate) < '2025-11-01'
  AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
UNION ALL
SELECT
  'Rejection Reason Breakdown' AS metric,
  COALESCE(SCORECARD_MODEL_DESCRIPTION_BRE__c, 'Not Available') AS rejection_reason,
  COUNT(*) AS count_of_applications,
  CAST(NULL AS FLOAT64) AS rejection_rate_pct
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.Sourcing_Data_11_Nov_25`
WHERE
  DATE(LastModifiedDate) >= '2025-10-01'
  AND DATE(LastModifiedDate) < '2025-11-01'
  AND SAFE_CAST(CIBIL_SCORE AS INT64) BETWEEN 300 AND 650
  AND BRE_Sanction_Result__c IN ('REJECT', 'Reject')
GROUP BY
  2
ORDER BY
  metric,
  count_of_applications DESC",
2ac4c8,2025-11-25 21:43:44.834187+00:00,7,1,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The value for the 'Last Year' delinquency percentage is incorrect. The candidate data shows 3.4, while the correct value is 5.34. The 'Current' value of 4.6 is correct.",0.69,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  'Current' AS period,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.DPD_BUCKET = 1 THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS delinquency_1_30_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
JOIN MaxDate
  ON T2.BUSINESS_DATE = MaxDate.max_business_date
WHERE
  T2.SOM_NPASTAGEID = 'REGULAR' AND T2.SOM_POS > 0
UNION ALL
SELECT
  'Last Year (Equivalent)' AS period,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Delinquency_1_30_LY_Flag = 1 THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS delinquency_1_30_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
JOIN MaxDate
  ON T2.BUSINESS_DATE = MaxDate.max_business_date
WHERE
  T2.SOM_NPASTAGEID = 'REGULAR' AND T2.SOM_POS > 0",
2ac4c8,2025-11-25 21:44:01.885582+00:00,7,2,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.75,0,0,"WITH DateAnchor AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), FilteredPortfolio AS (
  SELECT
    t.BUSINESS_DATE,
    t.AGREEMENTNO,
    t.DPD_BUCKET
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
  CROSS JOIN DateAnchor AS da
  WHERE
    (
      t.BUSINESS_DATE = da.max_dt
      OR t.BUSINESS_DATE = DATE_SUB(da.max_dt, INTERVAL '1' YEAR)
    )
    AND t.SOM_NPASTAGEID = 'REGULAR' /* Mandatory: Standard Performance */
    AND t.SOM_POS > 0 /* Mandatory: Active accounts */
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE
          WHEN fp.BUSINESS_DATE = (
            SELECT
              max_dt
            FROM DateAnchor
          )
          AND fp.DPD_BUCKET = 1
          THEN fp.AGREEMENTNO
        END
      ),
      COUNT(
        DISTINCT CASE
          WHEN fp.BUSINESS_DATE = (
            SELECT
              max_dt
            FROM DateAnchor
          )
          THEN fp.AGREEMENTNO
        END
      )
    ) * 100,
    2
  ) AS dpd_1_30_percentage_current_month,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE
          WHEN fp.BUSINESS_DATE = DATE_SUB((
            SELECT
              max_dt
            FROM DateAnchor
          ), INTERVAL '1' YEAR)
          AND fp.DPD_BUCKET = 1
          THEN fp.AGREEMENTNO
        END
      ),
      COUNT(
        DISTINCT CASE
          WHEN fp.BUSINESS_DATE = DATE_SUB((
            SELECT
              max_dt
            FROM DateAnchor
          ), INTERVAL '1' YEAR)
          THEN fp.AGREEMENTNO
        END
      )
    ) * 100,
    2
  ) AS dpd_1_30_percentage_last_year
FROM FilteredPortfolio AS fp",
2ac4c8,2025-11-25 21:44:13.043369+00:00,7,3,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.71,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentMonthData AS (
  SELECT
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS current_1_30_dpd_accounts,
    COUNT(DISTINCT AGREEMENTNO) AS current_total_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = (
      SELECT
        max_dt
      FROM MaxDate
    )
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
), LastYearMonthData AS (
  SELECT
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS last_year_1_30_dpd_accounts,
    COUNT(DISTINCT AGREEMENTNO) AS last_year_total_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = DATE_SUB((
      SELECT
        max_dt
      FROM MaxDate
    ), INTERVAL '1' YEAR)
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
)
SELECT
  ROUND(SAFE_DIVIDE(c.current_1_30_dpd_accounts, c.current_total_accounts) * 100, 2) AS current_1_30_dpd_percentage,
  ROUND(SAFE_DIVIDE(l.last_year_1_30_dpd_accounts, l.last_year_total_accounts) * 100, 2) AS last_year_1_30_dpd_percentage
FROM CurrentMonthData AS c
CROSS JOIN LastYearMonthData AS l",
2ac4c8,2025-11-25 21:44:20.002636+00:00,7,4,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,ERROR,Error: 400 Syntax error: Unexpected s,0.27,0,0,"WITH MaxBusinessDate AS (
    SELECT MAX(BUSINESS_DATE) AS current_date
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
),
CurrentMonthData AS (
    SELECT
        COUNT(DISTINCT AGREEMENTNO) AS total_accounts,
        COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS ""1_30_dpd_accounts""
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
    WHERE BUSINESS_DATE = (SELECT current_date FROM MaxBusinessDate)
      AND SOM_NPASTAGEID = 'REGULAR'
      AND SOM_POS > 0
),
LastYearData AS (
    SELECT
        COUNT(DISTINCT AGREEMENTNO) AS total_accounts,
        COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS ""1_30_dpd_accounts""
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
    WHERE BUSINESS_DATE = DATE_SUB((SELECT current_date FROM MaxBusinessDate), INTERVAL 1 YEAR)
      AND SOM_NPASTAGEID = 'REGULAR'
      AND SOM_POS > 0
)
SELECT
    (SELECT current_date FROM MaxBusinessDate) AS current_business_date,
    ROUND(SAFE_DIVIDE(c.1_30_dpd_accounts, c.total_accounts) * 100, 2) AS current_1_30_dpd_percentage,
    DATE_SUB((SELECT current_date FROM MaxBusinessDate), INTERVAL 1 YEAR) AS last_year_business_date,
    ROUND(SAFE_DIVIDE(l.1_30_dpd_accounts, l.total_accounts) * 100, 2) AS last_year_1_30_dpd_percentage
FROM CurrentMonthData c, LastYearData l","400 Syntax error: Unexpected string literal ""1_30_dpd_accounts"" at [8:74]; reason: invalidQuery, location: query, message: Syntax error: Unexpected string literal ""1_30_dpd_accounts"" at [8:74]

Location: asia-south1
Job ID: 14ca1a9d-cc28-4c97-a0bc-ab37135c65c9
"
2ac4c8,2025-11-25 21:44:28.309880+00:00,7,5,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,ERROR,Error: 400 Cannot GROUP BY field refe,0.51,0,0,"WITH DateAnchors AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), PortfolioData AS (
  SELECT
    t.BUSINESS_DATE,
    t.AGREEMENTNO,
    t.DPD_BUCKET
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
  JOIN DateAnchors AS da
    ON t.BUSINESS_DATE = da.max_business_date
    OR t.BUSINESS_DATE = DATE_SUB(da.max_business_date, INTERVAL '1' YEAR)
  WHERE
    t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
)
SELECT
  FORMAT_DATE('%Y-%m', current_month.BUSINESS_DATE) AS current_month,
  ROUND(
    SAFE_DIVIDE(
      SUM(CASE WHEN current_month.DPD_BUCKET = 1 THEN 1 ELSE 0 END),
      COUNT(DISTINCT current_month.AGREEMENTNO)
    ) * 100,
    2
  ) AS current_1_30_dpd_percentage,
  FORMAT_DATE('%Y-%m', last_year_month.BUSINESS_DATE) AS last_year_month,
  ROUND(
    SAFE_DIVIDE(
      SUM(CASE WHEN last_year_month.DPD_BUCKET = 1 THEN 1 ELSE 0 END),
      COUNT(DISTINCT last_year_month.AGREEMENTNO)
    ) * 100,
    2
  ) AS last_year_1_30_dpd_percentage
FROM PortfolioData AS current_month
LEFT JOIN PortfolioData AS last_year_month
  ON current_month.AGREEMENTNO = last_year_month.AGREEMENTNO
  AND last_year_month.BUSINESS_DATE = DATE_SUB(current_month.BUSINESS_DATE, INTERVAL '1' YEAR)
WHERE
  current_month.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM DateAnchors
  )
GROUP BY
  current_month.BUSINESS_DATE,
  last_year_month.BUSINESS_DATE
ORDER BY
  current_month.BUSINESS_DATE DESC
LIMIT 1","400 Cannot GROUP BY field references from SELECT list alias current_month at [45:3]; reason: invalidQuery, location: query, message: Cannot GROUP BY field references from SELECT list alias current_month at [45:3]

Location: asia-south1
Job ID: 1a46f494-1eaf-487e-98bb-e719cd7e883b
"
2ac4c8,2025-11-25 21:44:46.977729+00:00,7,6,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data correctly identifies the current 1-30 delinquency percentage as 4.6. However, it incorrectly reports the last year's percentage as 3.4, while the ground truth value is 5.34.",0.96,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  'Current Month' AS period,
  COUNT(DISTINCT CASE WHEN T2.DPD_BUCKET = 1 THEN T2.AGREEMENTNO END) AS current_1_30_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.DPD_BUCKET = 1 THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS current_1_30_dpd_percentage,
  COUNT(DISTINCT CASE WHEN T2.Delinquency_1_30_LY_Flag = 1 THEN T2.AGREEMENTNO END) AS last_year_1_30_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Delinquency_1_30_LY_Flag = 1 THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS last_year_1_30_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
CROSS JOIN MaxBusinessDate AS MBD
WHERE
  T2.BUSINESS_DATE = MBD.max_dt AND T2.SOM_NPASTAGEID = 'REGULAR' AND T2.SOM_POS > 0
GROUP BY
  1",
2ac4c8,2025-11-25 21:45:01.916309+00:00,7,7,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.7,0,0,"WITH DateAnchors AS (
  SELECT
    MAX(BUSINESS_DATE) AS current_max_date,
    DATE_SUB(MAX(BUSINESS_DATE), INTERVAL '1' YEAR) AS last_year_max_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentMonthData AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_accounts_current,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS del_1_30_accounts_current
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
  INNER JOIN DateAnchors AS da
    ON t.BUSINESS_DATE = da.current_max_date
  WHERE
    SOM_NPASTAGEID = 'REGULAR' AND SOM_POS > 0
), LastYearMonthData AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_accounts_last_year,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS del_1_30_accounts_last_year
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
  INNER JOIN DateAnchors AS da
    ON t.BUSINESS_DATE = da.last_year_max_date
  WHERE
    SOM_NPASTAGEID = 'REGULAR' AND SOM_POS > 0
)
SELECT
  ROUND(SAFE_DIVIDE(cmd.del_1_30_accounts_current, cmd.total_accounts_current) * 100, 2) AS current_1_30_delinquency_percentage,
  ROUND(
    SAFE_DIVIDE(lyd.del_1_30_accounts_last_year, lyd.total_accounts_last_year) * 100,
    2
  ) AS last_year_1_30_delinquency_percentage
FROM CurrentMonthData AS cmd
CROSS JOIN LastYearMonthData AS lyd",
2ac4c8,2025-11-25 21:45:20.387031+00:00,7,8,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data correctly identified the current 1-30 delinquency percentage as 4.6, but it provided an incorrect value for the previous year. The candidate returned 3.4, while the correct value is 5.34.",0.76,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 1 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS current_1_30_dpd_percentage, /* Current 1-30 DPD Percentage */
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.Delinquency_1_30_LY_Flag = 1 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS last_year_1_30_dpd_percentage /* Last Year's 1-30 DPD Percentage */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0",
2ac4c8,2025-11-25 21:45:30.103683+00:00,7,9,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.72,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentMonthData AS (
  SELECT
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS current_1_30_dpd_accounts,
    COUNT(DISTINCT AGREEMENTNO) AS current_total_active_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = (
      SELECT
        max_dt
      FROM MaxBusinessDate
    )
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
), LastYearMonthData AS (
  SELECT
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS last_year_1_30_dpd_accounts,
    COUNT(DISTINCT AGREEMENTNO) AS last_year_total_active_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = DATE_SUB((
      SELECT
        max_dt
      FROM MaxBusinessDate
    ), INTERVAL '1' YEAR)
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
)
SELECT
  ROUND(SAFE_DIVIDE(c.current_1_30_dpd_accounts, c.current_total_active_accounts) * 100, 2) AS current_1_30_dpd_percentage,
  ROUND(
    SAFE_DIVIDE(l.last_year_1_30_dpd_accounts, l.last_year_total_active_accounts) * 100,
    2
  ) AS last_year_1_30_dpd_percentage
FROM CurrentMonthData AS c
CROSS JOIN LastYearMonthData AS l",
2ac4c8,2025-11-25 21:45:49.167775+00:00,7,10,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data correctly identifies the current 1-30 delinquency percentage (4.6), but it provides an incorrect value for the last year's percentage. The candidate shows 2.86, while the ground truth is 5.34.",0.96,0,0,"WITH DateAnchor AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentMonthData AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_accounts,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS current_1_30_dpd_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = (
      SELECT
        max_business_date
      FROM DateAnchor
    )
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
), LastYearData AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_accounts_ly,
    COUNT(DISTINCT CASE WHEN Delinquency_1_30_LY_Flag = 1 THEN AGREEMENTNO END) AS last_year_1_30_dpd_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = DATE_SUB((
      SELECT
        max_business_date
      FROM DateAnchor
    ), INTERVAL '1' YEAR)
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
)
SELECT
  (
    SELECT
      max_business_date
    FROM DateAnchor
  ) AS current_date,
  (
    SELECT
      DATE_SUB(max_business_date, INTERVAL '1' YEAR)
    FROM DateAnchor
  ) AS last_year_date,
  COALESCE(ROUND(SAFE_DIVIDE(c.current_1_30_dpd_accounts, c.total_accounts) * 100, 2), 0) AS current_1_30_dpd_percentage,
  COALESCE(ROUND(SAFE_DIVIDE(l.last_year_1_30_dpd_accounts, l.total_accounts_ly) * 100, 2), 0) AS last_year_1_30_dpd_percentage
FROM CurrentMonthData AS c
CROSS JOIN LastYearData AS l",
2ac4c8,2025-11-25 21:46:12.430020+00:00,7,11,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data correctly identifies the current delinquency percentage as 4.6 and last year's as 5.34. The inclusion of extra columns with the underlying account counts is helpful context and does not detract from the correct answer.,0.71,0,0,"WITH MaxDates AS (
  SELECT
    MAX(BUSINESS_DATE) AS current_max_business_date,
    DATE_SUB(MAX(BUSINESS_DATE), INTERVAL '1' YEAR) AS last_year_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentPeriodData AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_active_accounts,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS dpd_1_30_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
  INNER JOIN MaxDates AS md
    ON t.BUSINESS_DATE = md.current_max_business_date
  WHERE
    t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
), LastYearPeriodData AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_active_accounts,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS dpd_1_30_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
  INNER JOIN MaxDates AS md
    ON t.BUSINESS_DATE = md.last_year_business_date
  WHERE
    t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
)
SELECT
  'Current Month' AS period,
  cm.total_active_accounts AS total_accounts,
  cm.dpd_1_30_accounts AS dpd_1_30_accounts,
  ROUND(SAFE_DIVIDE(cm.dpd_1_30_accounts, cm.total_active_accounts) * 100, 2) AS dpd_1_30_percentage
FROM CurrentPeriodData AS cm
UNION ALL
SELECT
  'Last Year' AS period,
  lym.total_active_accounts AS total_accounts,
  lym.dpd_1_30_accounts AS dpd_1_30_accounts,
  ROUND(SAFE_DIVIDE(lym.dpd_1_30_accounts, lym.total_active_accounts) * 100, 2) AS dpd_1_30_percentage
FROM LastYearPeriodData AS lym",
2ac4c8,2025-11-25 21:46:27.544962+00:00,7,12,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data correctly identifies the current 1-30 delinquency percentage as 4.6, but it incorrectly reports the value for last year as 3.4 instead of the correct 5.34.",1.26,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  CURRENT_DATE AS analysis_date,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.DPD_BUCKET = 1 THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS current_1_30_dpd_percentage, /* Current 1-30 DPD Percentage */
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Delinquency_1_30_LY_Flag = 1 THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS last_year_1_30_dpd_percentage /* Last Year 1-30 DPD Percentage (based on LY Flag) */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
INNER JOIN MaxBusinessDate AS M
  ON T2.BUSINESS_DATE = M.max_dt
WHERE
  T2.SOM_NPASTAGEID = 'REGULAR' AND T2.SOM_POS > 0",
2ac4c8,2025-11-25 21:46:49.099335+00:00,7,13,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data correctly identifies the current 1-30 delinquency percentage as 4.6, but it incorrectly reports last year's percentage as 3.4, whereas the ground truth is 5.34.",0.69,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), FilteredPortfolio AS (
  SELECT
    AGREEMENTNO,
    DPD_BUCKET,
    Delinquency_1_30_LY_Flag
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
  INNER JOIN MaxBusinessDate AS m
    ON t.BUSINESS_DATE = m.max_dt
  WHERE
    t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
)
SELECT
  COUNT(DISTINCT AGREEMENTNO) AS total_active_accounts_current_month,
  COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS current_month_1_30_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS current_month_1_30_dpd_percentage,
  COUNT(DISTINCT CASE WHEN Delinquency_1_30_LY_Flag = 1 THEN AGREEMENTNO END) AS last_year_same_month_1_30_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN Delinquency_1_30_LY_Flag = 1 THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS last_year_same_month_1_30_dpd_percentage
FROM FilteredPortfolio",
2ac4c8,2025-11-25 21:47:03.819983+00:00,7,14,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The value for the current 1-30 delinquency percentage is correct (4.6). However, the value for the last year's percentage is incorrect. The candidate returned 3.4, while the correct value is 5.34.",0.7,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentMonthData AS (
  SELECT
    AGREEMENTNO,
    DPD_BUCKET,
    Delinquency_1_30_LY_Flag
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = (
      SELECT
        max_dt
      FROM MaxBusinessDate
    )
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T.DPD_BUCKET = 1 THEN T.AGREEMENTNO END),
      COUNT(DISTINCT T.AGREEMENTNO)
    ) * 100,
    2
  ) AS current_month_1_30_dpd_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T.Delinquency_1_30_LY_Flag = 1 THEN T.AGREEMENTNO END),
      COUNT(DISTINCT T.AGREEMENTNO)
    ) * 100,
    2
  ) AS last_year_1_30_dpd_percentage
FROM CurrentMonthData AS T",
2ac4c8,2025-11-25 21:47:22.611962+00:00,7,15,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the current delinquency percentage (4.6) and the percentage from the same period last year (5.34). Although the data is structured differently (long format with two rows vs. wide format with one row), the semantic meaning and the core numerical values are identical to the ground truth.",0.94,0,0,"WITH DateAnchor AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  'Current Month' AS period,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t1.DPD_BUCKET = 1 THEN t1.AGREEMENTNO END),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS current_1_30_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN DateAnchor AS da
WHERE
  t1.BUSINESS_DATE = da.max_business_date
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
UNION ALL
SELECT
  'Last Year Same Month' AS period,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t2.DPD_BUCKET = 1 THEN t2.AGREEMENTNO END),
      COUNT(DISTINCT t2.AGREEMENTNO)
    ) * 100,
    2
  ) AS last_year_1_30_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
CROSS JOIN DateAnchor AS da
WHERE
  t2.BUSINESS_DATE = DATE_SUB(da.max_business_date, INTERVAL '1' YEAR)
  AND t2.SOM_NPASTAGEID = 'REGULAR'
  AND t2.SOM_POS > 0",
2ac4c8,2025-11-25 21:47:41.408333+00:00,7,16,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the delinquency percentages for the current year (4.6) and last year (5.34). Although the format is different (long vs. wide), the data is semantically equivalent to the ground truth.",0.8,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  'Current Year' AS period,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS delinquency_1_30_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      max_dt
    FROM MaxBusinessDate
  )
  AND SOM_NPASTAGEID = 'REGULAR'
  AND SOM_POS > 0
UNION ALL
SELECT
  'Last Year' AS period,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS delinquency_1_30_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = DATE_SUB((
    SELECT
      max_dt
    FROM MaxBusinessDate
  ), INTERVAL '1' YEAR)
  AND SOM_NPASTAGEID = 'REGULAR'
  AND SOM_POS > 0",
2ac4c8,2025-11-25 21:48:00.338906+00:00,7,17,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the current delinquency percentage as 4.6 and last year's as 5.34, which matches the ground truth. The inclusion of specific dates is considered helpful extra information.",0.71,0,0,"WITH MaxDates AS (
  SELECT
    MAX(BUSINESS_DATE) AS current_max_date,
    DATE_SUB(MAX(BUSINESS_DATE), INTERVAL '1' YEAR) AS last_year_comparable_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentPortfolio AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS current_total_accounts,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS current_1_30_dpd_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = (
      SELECT
        current_max_date
      FROM MaxDates
    )
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
), LastYearPortfolio AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS last_year_total_accounts,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS last_year_1_30_dpd_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = (
      SELECT
        last_year_comparable_date
      FROM MaxDates
    )
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
)
SELECT
  (
    SELECT
      current_max_date
    FROM MaxDates
  ) AS current_date,
  ROUND(SAFE_DIVIDE(c.current_1_30_dpd_accounts, c.current_total_accounts) * 100, 2) AS current_1_30_dpd_percentage,
  (
    SELECT
      last_year_comparable_date
    FROM MaxDates
  ) AS last_year_date,
  ROUND(SAFE_DIVIDE(l.last_year_1_30_dpd_accounts, l.last_year_total_accounts) * 100, 2) AS last_year_1_30_dpd_percentage
FROM CurrentPortfolio AS c
CROSS JOIN LastYearPortfolio AS l",
2ac4c8,2025-11-25 21:48:06.747103+00:00,7,18,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,ERROR,Error: 400 Syntax error: Unexpected s,0.39,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS current_max_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentMonthData AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_accounts,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS `1_30_dpd_accounts`
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = (
      SELECT
        current_max_date
      FROM MaxBusinessDate
    )
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
), LastYearMonthData AS (
  SELECT
    COUNT(DISTINCT AGREEMENTNO) AS total_accounts_ly,
    COUNT(DISTINCT CASE WHEN DPD_BUCKET = 1 THEN AGREEMENTNO END) AS `1_30_dpd_accounts_ly`
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  WHERE
    BUSINESS_DATE = DATE_SUB((
      SELECT
        current_max_date
      FROM MaxBusinessDate
    ), INTERVAL '1' YEAR)
    AND SOM_NPASTAGEID = 'REGULAR'
    AND SOM_POS > 0
)
SELECT
  ROUND(SAFE_DIVIDE(cmd.'1_30_dpd_accounts', cmd.total_accounts) * 100, 2) AS current_1_30_dpd_percentage,
  ROUND(SAFE_DIVIDE(lymd.'1_30_dpd_accounts_ly', lymd.total_accounts_ly) * 100, 2) AS last_year_1_30_dpd_percentage
FROM CurrentMonthData AS cmd
CROSS JOIN LastYearMonthData AS lymd","400 Syntax error: Unexpected string literal '1_30_dpd_accounts' at [33:25]; reason: invalidQuery, location: query, message: Syntax error: Unexpected string literal '1_30_dpd_accounts' at [33:25]

Location: asia-south1
Job ID: d83bbc4c-4506-4840-b398-3aeb7dba7d88
"
2ac4c8,2025-11-25 21:48:32.598985+00:00,7,19,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the current 1-30 delinquency percentage as 4.6 and last year's as 5.34. The additional columns provide helpful context on how the percentages were derived, which is acceptable.",0.71,0,0,"WITH DateAnchors AS (
  SELECT
    MAX(BUSINESS_DATE) AS current_max_business_date,
    DATE_SUB(MAX(BUSINESS_DATE), INTERVAL '1' YEAR) AS last_year_max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
), CurrentMonthData AS (
  SELECT
    'Current Month' AS period,
    da.current_max_business_date AS business_date,
    COUNT(DISTINCT t.AGREEMENTNO) AS total_active_accounts,
    COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 1 THEN t.AGREEMENTNO END) AS del_1_30_dpd_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
  INNER JOIN DateAnchors AS da
    ON t.BUSINESS_DATE = da.current_max_business_date
  WHERE
    t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
  GROUP BY
    1,
    2
), LastYearMonthData AS (
  SELECT
    'Last Year Month' AS period,
    da.last_year_max_business_date AS business_date,
    COUNT(DISTINCT t.AGREEMENTNO) AS total_active_accounts,
    COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 1 THEN t.AGREEMENTNO END) AS del_1_30_dpd_accounts
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
  INNER JOIN DateAnchors AS da
    ON t.BUSINESS_DATE = da.last_year_max_business_date
  WHERE
    t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
  GROUP BY
    1,
    2
)
SELECT
  period,
  business_date,
  COALESCE(total_active_accounts, 0) AS total_active_accounts,
  COALESCE(del_1_30_dpd_accounts, 0) AS del_1_30_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(COALESCE(del_1_30_dpd_accounts, 0), COALESCE(total_active_accounts, 0)) * 100,
    2
  ) AS del_1_30_dpd_percentage
FROM CurrentMonthData
UNION ALL
SELECT
  period,
  business_date,
  COALESCE(total_active_accounts, 0) AS total_active_accounts,
  COALESCE(del_1_30_dpd_accounts, 0) AS del_1_30_dpd_accounts,
  ROUND(
    SAFE_DIVIDE(COALESCE(del_1_30_dpd_accounts, 0), COALESCE(total_active_accounts, 0)) * 100,
    2
  ) AS del_1_30_dpd_percentage
FROM LastYearMonthData
ORDER BY
  business_date DESC",
2ac4c8,2025-11-25 21:48:51.561432+00:00,7,20,what is the current 1-30 delinquency percentage of the portfolio in comparison with last year?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate data correctly identifies the current 1-30 delinquency percentage as 4.6, but it incorrectly reports last year's percentage as 3.4 instead of the correct value, 5.34.",0.82,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.DPD_BUCKET = 1 THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS current_1_30_dpd_percentage,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN T2.Delinquency_1_30_LY_Flag = 1 THEN T2.AGREEMENTNO END),
      COUNT(DISTINCT T2.AGREEMENTNO)
    ) * 100,
    2
  ) AS last_year_1_30_dpd_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS T2
JOIN MaxDate
  ON T2.BUSINESS_DATE = MaxDate.max_business_date
WHERE
  T2.SOM_NPASTAGEID = 'REGULAR' AND T2.SOM_POS > 0",
2ac4c8,2025-11-25 21:48:58.552220+00:00,8,1,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.89,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0",
2ac4c8,2025-11-25 21:49:09.943227+00:00,8,2,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,FAIL,LLM: The candidate's calculated count of 60806 does not match the ground truth count of 60803. The values are different.,0.68,0,0,"SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1",
2ac4c8,2025-11-25 21:49:17.113270+00:00,8,3,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.75,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT t1.AGREEMENTNO) AS cases_slipped_from_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate AS m
WHERE
  t1.BUSINESS_DATE = m.max_business_date
  AND t1.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND t1.SOM_POS > 0",
2ac4c8,2025-11-25 21:49:23.464012+00:00,8,4,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.7,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT t1.AGREEMENTNO) AS cases_slipped_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
INNER JOIN MaxDate AS t2
  ON t1.BUSINESS_DATE = t2.dt
WHERE
  t1.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1 AND t1.SOM_POS > 0",
2ac4c8,2025-11-25 21:49:29.184650+00:00,8,5,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.88,0,0,"SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0",
2ac4c8,2025-11-25 21:49:35.262706+00:00,8,6,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.68,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_from_0_ly_to_90_plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0",
2ac4c8,2025-11-25 21:49:41.273157+00:00,8,7,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.97,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_from_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      max_dt
    FROM MaxDate
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0",
2ac4c8,2025-11-25 21:49:47.244549+00:00,8,8,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.68,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_from_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      max_dt
    FROM MaxDate
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0",
2ac4c8,2025-11-25 21:49:59.100050+00:00,8,9,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,FAIL,LLM: The candidate's result of 60806 does not match the ground truth value of 60803. The counts are different.,0.7,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT t1.AGREEMENTNO) AS cases_slipped_from_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
INNER JOIN MaxDate AS t2
  ON t1.BUSINESS_DATE = t2.max_dt
WHERE
  t1.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1",
2ac4c8,2025-11-25 21:50:10.030305+00:00,8,10,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,FAIL,LLM: The candidate's result of 60806 does not match the ground truth value of 60803. The values are different.,0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1",
2ac4c8,2025-11-25 21:50:15.434501+00:00,8,11,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_from_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      max_dt
    FROM MaxDate
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0",
2ac4c8,2025-11-25 21:50:21.917767+00:00,8,12,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT t1.AGREEMENTNO) AS cases_slipped_from_0_ly_to_90_plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
INNER JOIN MaxDate AS t2
  ON t1.BUSINESS_DATE = t2.dt
WHERE
  t1.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1 AND t1.SOM_POS > 0",
2ac4c8,2025-11-25 21:50:28.069232+00:00,8,13,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.69,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT t1.AGREEMENTNO) AS cases_0LY_slipped_to_90PLUS_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
WHERE
  t1.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t1.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND t1.SOM_POS > 0",
2ac4c8,2025-11-25 21:50:33.410686+00:00,8,14,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.66,0,0,"SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_0ly_to_90plus
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0",
2ac4c8,2025-11-25 21:50:44.672984+00:00,8,15,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,FAIL,"LLM: The candidate's calculated value is 60806, which does not match the ground truth value of 60803. The counts are different.",0.66,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_from_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1",
2ac4c8,2025-11-25 21:50:58.112164+00:00,8,16,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,FAIL,LLM: The candidate's result of 60806 does not match the ground truth value of 60803. The values are different.,0.81,0,0,"SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1",
2ac4c8,2025-11-25 21:51:05.291600+00:00,8,17,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.69,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT t1.AGREEMENTNO) AS cases_slipped_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxBusinessDate AS t2
WHERE
  t1.BUSINESS_DATE = t2.max_dt
  AND t1.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND t1.SOM_POS > 0",
2ac4c8,2025-11-25 21:51:11.363472+00:00,8,18,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.72,0,0,"SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_0LY_to_90_plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0",
2ac4c8,2025-11-25 21:51:17.118459+00:00,8,19,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.67,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT t1.AGREEMENTNO) AS cases_slipped_from_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
INNER JOIN MaxDate
  ON t1.BUSINESS_DATE = MaxDate.dt
WHERE
  t1.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1 AND t1.SOM_POS > 0",
2ac4c8,2025-11-25 21:51:23.312308+00:00,8,20,How many cases who were at 0 delinquency last year and now have slipped to 90+ ?,Collections,DomainType.COLLECTIONS,PASS,Numeric Exact Match,0.79,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  COUNT(DISTINCT AGREEMENTNO) AS cases_slipped_from_0ly_to_90plus_current
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0",
2ac4c8,2025-11-25 21:51:40.580291+00:00,9,1,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data is a perfect match. All rows and corresponding values are identical to the ground truth. The difference in column names ('total_bucket_1_count' vs 'total_bucket_1_accounts' and 'normalization_rate' vs 'normalization_rate_percentage') is acceptable as per the evaluation criteria.,0.68,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  UPPER(STATE) AS state,
  COUNT(DISTINCT CASE WHEN DPD_BUCKET = 0 THEN AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN DPD_BUCKET = 0 THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  1
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:51:58.070300+00:00,9,2,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. All states, counts, and normalization rates are identical. The difference in column names is acceptable as the values are semantically equivalent.",0.71,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalized_accounts_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_accounts_in_som_dpd_bucket_1,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate AS md
WHERE
  t.BUSINESS_DATE = md.max_business_date
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:52:15.440102+00:00,9,3,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data is a perfect match. All rows and corresponding values are identical to the ground truth. The difference in column names ('total_bucket_1_count' vs 'total_bucket_1_accounts' and 'normalization_rate' vs 'normalization_rate_percentage') is acceptable as per the evaluation criteria.,0.87,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  STATE,
  COUNT(DISTINCT CASE WHEN DPD_BUCKET = 0 THEN AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN DPD_BUCKET = 0 THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND SOM_DPD_BUCKET = 1
  AND SOM_NPASTAGEID = 'REGULAR'
  AND SOM_POS > 0
GROUP BY
  STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:52:29.255130+00:00,9,4,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data provides the correct states and corresponding normalization rates, perfectly matching the ground truth values. The difference in column names is acceptable as per the evaluation criteria.",0.76,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  STATE,
  COUNT(DISTINCT CASE WHEN DPD_BUCKET = 0 THEN AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN DPD_BUCKET = 0 THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND SOM_DPD_BUCKET = 1
  AND SOM_NPASTAGEID = 'REGULAR'
  AND SOM_POS > 0
GROUP BY
  STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:52:46.282331+00:00,9,5,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. It correctly identifies the top 5 states and their corresponding normalization metrics. The column names are different but semantically equivalent, which is acceptable.",0.67,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:53:04.951639+00:00,9,6,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data is a perfect match. All rows and corresponding values are identical to the ground truth. The difference in column names ('total_bucket_1_count' vs 'total_bucket_1_accounts' and 'normalization_rate' vs 'normalization_rate_percentage') is acceptable as per the evaluation criteria.,0.85,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:53:20.030886+00:00,9,7,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data provides the correct states and corresponding normalization rates, perfectly matching the ground truth values. The difference in column names is acceptable as per the evaluation criteria.",0.7,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:53:35.496085+00:00,9,8,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is an exact match to the ground truth data, with all rows and values being identical.",0.75,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 1 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 21:53:51.872750+00:00,9,9,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. It correctly identifies the top 5 states and their corresponding normalization metrics. The column names are different but semantically equivalent, which is acceptable.",0.88,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_dt
    FROM MaxBusinessDate
  )
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:54:12.919340+00:00,9,10,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. All values, rows, and the ranking order are identical. The difference in the column name 'total_bucket_1_count' vs 'total_bucket_1_accounts' is ignored as per the evaluation criteria.",0.79,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  STATE,
  COUNT(DISTINCT CASE WHEN DPD_BUCKET = 0 THEN AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN DPD_BUCKET = 0 THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_dt
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  STATE
ORDER BY
  normalization_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 21:54:28.313091+00:00,9,11,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data provides the correct states and corresponding normalization rates, perfectly matching the ground truth values. The difference in column names is acceptable as per the evaluation criteria.",0.88,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 1 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:54:46.390385+00:00,9,12,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. All values, rows, and the ranking order are identical. The difference in the column name 'total_bucket_1_count' vs 'total_bucket_1_accounts' is ignored as per the evaluation criteria.",0.96,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxBusinessDate AS m
WHERE
  t.BUSINESS_DATE = m.max_date
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 21:55:04.825437+00:00,9,13,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. All values, rows, and the ranking order are identical. The difference in the column name 'total_bucket_1_count' vs 'total_bucket_1_accounts' is ignored as per the evaluation criteria.",0.96,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  STATE,
  COUNT(DISTINCT CASE WHEN (
    t.DPD_BUCKET = 0
  ) THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN (
        t.DPD_BUCKET = 0
      ) THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate
  ON t.BUSINESS_DATE = MaxDate.dt
WHERE
  t.SOM_DPD_BUCKET = 1 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  STATE
ORDER BY
  normalization_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 21:55:20.475207+00:00,9,14,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data provides the correct values for all states, counts, and rates, perfectly matching the ground truth. The difference in column names is acceptable as the underlying data is identical.",0.71,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 1 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:55:36.823930+00:00,9,15,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. It correctly identifies the top 5 states and their corresponding normalization metrics. The column names are different but semantically equivalent, which is acceptable.",0.91,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:55:55.165639+00:00,9,16,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data is a perfect match. All rows and corresponding values are identical to the ground truth. The difference in column names ('total_bucket_1_count' vs 'total_bucket_1_accounts' and 'normalization_rate' vs 'normalization_rate_percentage') is acceptable as per the evaluation criteria.,0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate AS md
WHERE
  t.BUSINESS_DATE = md.max_business_date
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:56:10.995937+00:00,9,17,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is an exact match to the ground truth data, with all rows and values being identical.",0.74,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  STATE,
  COUNT(DISTINCT CASE WHEN DPD_BUCKET = 0 THEN AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT AGREEMENTNO) AS total_bucket_1_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN DPD_BUCKET = 0 THEN AGREEMENTNO END),
      COUNT(DISTINCT AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND SOM_DPD_BUCKET = 1
  AND SOM_NPASTAGEID = 'REGULAR'
  AND SOM_POS > 0
GROUP BY
  STATE
ORDER BY
  normalization_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 21:56:27.347116+00:00,9,18,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data provides the correct states and corresponding normalization rates, perfectly matching the ground truth values. The difference in column names is acceptable as per the evaluation criteria.",1.05,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.dt
WHERE
  t.SOM_DPD_BUCKET = 1 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:56:43.626386+00:00,9,19,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data is an exact match to the ground truth data. All rows and corresponding values are identical.,0.93,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_1_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 1
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 21:57:02.051186+00:00,9,20,Which state has the highest normalization rate for the current month in DPD BKT 1?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. Although the column names differ, the values, row count, and ranking are identical, which satisfies the evaluation criteria.",0.94,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END) AS normalization_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_accounts_in_dpd_bucket_1,
  ROUND(
    SAFE_DIVIDE(
      COUNT(DISTINCT CASE WHEN t.DPD_BUCKET = 0 THEN t.AGREEMENTNO END),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS normalization_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 1 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  normalization_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:57:21.613600+00:00,10,1,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data is a perfect match to the ground truth. All rows and corresponding values are identical. The difference in column names ('total_bucket_1_count' vs 'total_bucket_2_count' and 'roll_forward_rate' vs 'roll_forward_rate_percentage') is ignored as per the evaluation criteria.,0.72,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 2
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:57:40.040106+00:00,10,2,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,LLM: The candidate data is a perfect match to the ground truth. All rows and corresponding values are identical. The difference in column names ('total_bucket_1_count' vs 'total_bucket_2_count' and 'roll_forward_rate' vs 'roll_forward_rate_percentage') is ignored as per the evaluation criteria.,0.68,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS m
  ON t.BUSINESS_DATE = m.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:57:59.827865+00:00,10,3,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. All states, counts, and roll forward rates are identical. The difference in column names is ignored as per the instructions.",0.76,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS m
  ON t.BUSINESS_DATE = m.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 21:58:17.803106+00:00,10,4,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data perfectly matches the ground truth in terms of states, counts, and roll forward rates. The difference in column names ('total_bucket_1_count' vs 'total_bucket_2_count') is ignored as per the evaluation criteria.",0.65,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 21:58:38.537979+00:00,10,5,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. All rows and corresponding data values are identical. The difference in column names ('total_bucket_1_count' vs 'total_bucket_2_count') is ignored as per the evaluation criteria, as the underlying data is the same.",0.85,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS m
  ON t.BUSINESS_DATE = m.dt
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 21:58:56.455679+00:00,10,6,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data perfectly matches the ground truth data in terms of values, row count, and ranking. The difference in column names ('total_bucket_1_count' vs 'total_bucket_2_accounts') is ignored as per the evaluation criteria.",0.71,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.dt
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 21:59:14.030769+00:00,10,7,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 5 states with the highest roll forward rates. All numerical values and state names match the ground truth. The difference in the column name ('total_bucket_2_count' vs 'total_bucket_1_count') is ignored as per the evaluation criteria, since the underlying data is identical.",1.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 21:59:37.005585+00:00,10,8,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data perfectly matches the ground truth data in terms of values, row count, and ranking. The difference in column names ('total_bucket_1_count' vs 'total_bucket_2_accounts') is ignored as per the evaluation criteria.",0.87,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 21:59:55.831064+00:00,10,9,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 5 states with the highest roll forward rates. All numerical values and state names match the ground truth. The difference in the column name ('total_bucket_2_count' vs 'total_bucket_1_count') is ignored as per the evaluation criteria, since the underlying data is identical.",0.81,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_dt
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 22:00:12.062317+00:00,10,10,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. Although one column name differs ('total_bucket_1_count' vs 'total_bucket_2_accounts'), the evaluation criteria state to ignore column names and focus on the values, which are identical across all columns and rows.",0.84,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 2
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 22:00:33.069419+00:00,10,11,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. All rows and corresponding data values are identical. The difference in the column name ('total_bucket_1_count' vs 'total_bucket_2_count') is disregarded as per the evaluation criteria, since the values within the columns are the same.",0.89,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 22:00:54.208325+00:00,10,12,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. All states, counts, and roll forward rates are identical. The difference in column names is acceptable as per the evaluation criteria.",0.85,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 22:01:13.199548+00:00,10,13,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 5 states with the highest roll forward rates, and all corresponding values for counts and rates are identical to the ground truth.",0.74,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_accounts_in_dpd_bkt_2_som,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 2
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 22:01:33.983690+00:00,10,14,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data perfectly matches the ground truth data in terms of values, row count, and ranking. The difference in column names ('total_bucket_1_count' vs 'total_bucket_2_accounts') is ignored as per the evaluation criteria.",0.74,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate
WHERE
  t.BUSINESS_DATE = MaxDate.dt
  AND t.SOM_DPD_BUCKET = 2
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 22:01:51.245497+00:00,10,15,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data is a perfect match to the ground truth. All rows and corresponding values are identical, correctly answering the user's question.",1.03,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 2
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate_percentage DESC
LIMIT 5",
2ac4c8,2025-11-25 22:02:09.226147+00:00,10,16,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data correctly identifies the top 5 states with the highest roll forward rates, and the values for these states perfectly match the ground truth. The candidate provides additional, correctly ranked rows, which is acceptable as it still answers the core question.",0.91,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 10",
2ac4c8,2025-11-25 22:02:27.729682+00:00,10,17,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,PASS,"LLM: The candidate data perfectly matches the ground truth data in terms of values, row count, and ranking. The difference in column names ('total_bucket_1_count' vs 'total_bucket_2_accounts') is ignored as per the evaluation criteria.",0.77,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_accounts,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t.SOM_DPD_BUCKET = 2
  AND t.SOM_NPASTAGEID = 'REGULAR'
  AND t.SOM_POS > 0
GROUP BY
  STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5",
2ac4c8,2025-11-25 22:02:33.148941+00:00,10,18,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,ERROR,Error: string indices must be integer,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  t.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:02:40.150388+00:00,10,19,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,ERROR,Error: string indices must be integer,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t1.STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t1.DPD_BUCKET - t1.SOM_DPD_BUCKET
    ) > 0 THEN t1.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t1.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t1.DPD_BUCKET - t1.SOM_DPD_BUCKET
        ) > 0 THEN t1.AGREEMENTNO END
      ),
      COUNT(DISTINCT t1.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate AS m
WHERE
  t1.BUSINESS_DATE = m.max_dt
  AND t1.SOM_DPD_BUCKET = 2
  AND t1.SOM_NPASTAGEID = 'REGULAR'
  AND t1.SOM_POS > 0
GROUP BY
  t1.STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:02:47.064996+00:00,10,20,Which state has the highest roll forward rate for the current month in DPD BKT 2?,Collections,DomainType.COLLECTIONS,ERROR,Error: string indices must be integer,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  STATE,
  COUNT(
    DISTINCT CASE WHEN (
      t.DPD_BUCKET - t.SOM_DPD_BUCKET
    ) > 0 THEN t.AGREEMENTNO END
  ) AS roll_forward_count,
  COUNT(DISTINCT t.AGREEMENTNO) AS total_bucket_2_count,
  ROUND(
    SAFE_DIVIDE(
      COUNT(
        DISTINCT CASE WHEN (
          t.DPD_BUCKET - t.SOM_DPD_BUCKET
        ) > 0 THEN t.AGREEMENTNO END
      ),
      COUNT(DISTINCT t.AGREEMENTNO)
    ) * 100,
    2
  ) AS roll_forward_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.SOM_DPD_BUCKET = 2 AND t.SOM_NPASTAGEID = 'REGULAR' AND t.SOM_POS > 0
GROUP BY
  STATE
ORDER BY
  roll_forward_rate DESC
LIMIT 5","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:03:02.756591+00:00,11,1,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS business_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_30_plus_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE >= DATE_SUB((
    SELECT
      max_dt
    FROM MaxBusinessDate
  ), INTERVAL '12' MONTH)
  AND t.BUSINESS_DATE <= (
    SELECT
      max_dt
    FROM MaxBusinessDate
  )
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:03:07.807034+00:00,11,2,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS business_month,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_3MOB), SUM(t1.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_30_plus_percentage /* Calculate 30+ delinquency percentage at MOB 3 */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate AS t2
WHERE
  t1.BUSINESS_DATE = t2.max_business_date
GROUP BY
  1
ORDER BY
  1 DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:03:17.041326+00:00,11,3,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS business_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_30_plus_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE >= DATE_SUB(md.max_dt, INTERVAL '6' MONTH)
GROUP BY
  business_month
ORDER BY
  business_month DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:03:23.972549+00:00,11,4,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS latest_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_3MOB), SUM(t2.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
WHERE
  t2.BUSINESS_DATE = (
    SELECT
      latest_business_date
    FROM MaxDate
  )","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:03:35.671327+00:00,11,5,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS reporting_month,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_3MOB), SUM(t1.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_30_plus_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxBusinessDate AS m
WHERE
  t1.BUSINESS_DATE = m.max_dt
GROUP BY
  1
ORDER BY
  1 DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:03:44.447513+00:00,11,6,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage /* No grouping by date_trunc, as the request is for the overall portfolio's current performance */ /* for MOB 3, which is captured by the max_business_date filter. */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  ) /* For vintage/risk metrics like NR_30_PLUS_3MOB and DR_30_PLUS_3MOB, */ /* we do not apply SOM_NPASTAGEID = 'REGULAR' or SOM_POS > 0, */ /* as these pre-calculated columns already account for the population relevant to delinquency at that MOB. */","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:03:58.986503+00:00,11,7,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS snapshot_month,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_3MOB), SUM(t1.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxBusinessDate AS mbd
WHERE
  t1.BUSINESS_DATE = mbd.max_dt
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:04:14.736327+00:00,11,8,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
GROUP BY
  1
ORDER BY
  1 DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:04:22.733470+00:00,11,9,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_3MOB), SUM(DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_30_plus_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:04:26.406647+00:00,11,10,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_30_plus_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:04:35.565630+00:00,11,11,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage /* Direct calculation using pre-defined mart columns for MOB 3, 30+ DPD delinquency */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:04:43.006010+00:00,11,12,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_3MOB), SUM(DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:04:59.646873+00:00,11,13,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.BUSINESS_DATE, MONTH) AS analysis_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_30_plus_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxBusinessDate AS m
WHERE
  t.BUSINESS_DATE /* Retrieve data for the last 12 months to show performance trend */ >= DATE_TRUNC(DATE_SUB(m.max_dt, INTERVAL '11' MONTH), MONTH)
  AND t.BUSINESS_DATE <= m.max_dt
/* For risk analysis (30+ delinquency), we do not filter for 'REGULAR' */
GROUP BY
  1
ORDER BY
  1 DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:05:05.693202+00:00,11,14,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_3MOB), SUM(DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:05:18.602633+00:00,11,15,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS analysis_month,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_3MOB), SUM(t1.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_30_plus_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
JOIN MaxDate AS t2
  ON t1.BUSINESS_DATE >= DATE_SUB(t2.max_dt, INTERVAL '6' MONTH)
GROUP BY
  analysis_month
ORDER BY
  analysis_month DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:05:23.971324+00:00,11,16,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_3MOB), SUM(DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:05:30.977230+00:00,11,17,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t2.BUSINESS_DATE, MONTH) AS business_month,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_3MOB), SUM(t2.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
INNER JOIN MaxBusinessDate AS mbd
  ON t2.BUSINESS_DATE = mbd.max_dt
GROUP BY
  1
ORDER BY
  1 DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:05:36.146299+00:00,11,18,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS business_month,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_3MOB), SUM(t1.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage /* Calculate 30+ DPD performance at MOB 3 */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate
WHERE
  t1.BUSINESS_DATE = MaxDate.max_business_date
GROUP BY
  1
ORDER BY
  1 DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:05:42.159923+00:00,11,19,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_3MOB), SUM(t1.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
WHERE
  t1.BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:05:53.765717+00:00,11,20,How is the portfolio performing at MOB 3 for 30+ delinquency?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.BUSINESS_DATE, MONTH) AS business_month,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_3MOB), SUM(t1.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage /* Calculate 30+ Delinquency Rate at MOB 3 */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate
WHERE
  t1.BUSINESS_DATE = MaxDate.max_business_date
GROUP BY
  1
ORDER BY
  1 DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:06:00.177156+00:00,12,1,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_3MOB), SUM(t1.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_rate,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_6MOB), SUM(t1.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_rate,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_9MOB), SUM(t1.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_rate,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_12MOB), SUM(t1.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
JOIN MaxBusinessDate AS m
  ON t1.BUSINESS_DATE = m.max_dt
WHERE
  t1.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  disbursal_month
ORDER BY
  disbursal_month","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:06:05.715935+00:00,12,2,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_30_plus_delinquency_rate, /* MOB 3 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_30_plus_delinquency_rate, /* MOB 6 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_30_plus_delinquency_rate, /* MOB 9 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_30_plus_delinquency_rate /* MOB 12 Rate */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:06:14.951276+00:00,12,3,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_percentage,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_percentage,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxBusinessDate AS m
WHERE
  t.BUSINESS_DATE = m.max_dt
  AND t.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:06:22.331397+00:00,12,4,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_rate_30_plus, /* MOB 3 Delinquency Rate (30+ DPD) */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_rate_30_plus, /* MOB 6 Delinquency Rate (30+ DPD) */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_rate_30_plus, /* MOB 9 Delinquency Rate (30+ DPD) */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_rate_30_plus /* MOB 12 Delinquency Rate (30+ DPD) */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.DISBURSALDATE >= '2024-01-01'
  AND t.DISBURSALDATE < '2024-04-01' /* Filter for Jan, Feb, Mar 2024 disbursals */
GROUP BY
  disbursal_month
ORDER BY
  disbursal_month","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:06:29.528063+00:00,12,5,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_rate, /* MOB 3 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_rate, /* MOB 6 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_rate, /* MOB 9 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_rate /* MOB 12 Rate for 30+ Delinquency */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxBusinessDate AS mbd
WHERE
  t.BUSINESS_DATE = mbd.max_dt
  AND t.DISBURSALDATE >= '2024-01-01'
  AND t.DISBURSALDATE < '2024-04-01' /* Ensures Jan, Feb, Mar 2024 disbursements */
GROUP BY
  disbursal_month
ORDER BY
  disbursal_month","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:06:35.672847+00:00,12,6,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage, /* MOB 3 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_percentage, /* MOB 6 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_percentage, /* MOB 9 Rate (assuming NR_30_PLUS_9MOB and DR_30_PLUS_9MOB exist based on the pattern) */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_percentage /* MOB 12 Rate */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
  AND t.BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:06:48.265118+00:00,12,7,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  DATE_TRUNC(t2.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_3MOB), SUM(t2.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage, /* MOB 3 Rate */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_6MOB), SUM(t2.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_percentage, /* MOB 6 Rate */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_9MOB), SUM(t2.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_percentage, /* MOB 9 Rate */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_12MOB), SUM(t2.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_percentage /* MOB 12 Rate */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
WHERE
  t2.DISBURSALDATE >= '2024-01-01'
  AND t2.DISBURSALDATE < '2024-04-01' /* Covers Jan, Feb, Mar 2024 */
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:06:56.608997+00:00,12,8,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDates AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage, /* MOB 3 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_percentage, /* MOB 6 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_percentage, /* MOB 9 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_percentage /* MOB 12 Rate */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDates AS md
WHERE
  t.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
  AND t.BUSINESS_DATE = md.max_business_date
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:07:04.421992+00:00,12,9,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage, /* MOB 3 Performance */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_percentage, /* MOB 6 Performance */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_percentage, /* MOB 9 Performance */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_percentage /* MOB 12 Performance */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:07:10.931087+00:00,12,10,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage, /* MOB 3 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_percentage, /* MOB 6 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_percentage, /* MOB 9 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_percentage /* MOB 12 Rate */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxBusinessDate AS mbd
WHERE
  t.BUSINESS_DATE = mbd.max_dt
  AND t.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:07:17.389189+00:00,12,11,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t2.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_3MOB), SUM(t2.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_rate_30_plus, /* MOB 3 Delinquency Rate (30+ DPD) */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_6MOB), SUM(t2.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_rate_30_plus, /* MOB 6 Delinquency Rate (30+ DPD) */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_9MOB), SUM(t2.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_rate_30_plus, /* MOB 9 Delinquency Rate (30+ DPD) */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_12MOB), SUM(t2.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_rate_30_plus /* MOB 12 Delinquency Rate (30+ DPD) */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
JOIN MaxDate AS md
  ON t2.BUSINESS_DATE = md.max_business_date
WHERE
  t2.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:07:28.303111+00:00,12,12,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t2.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_3MOB), SUM(t2.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_rate,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_6MOB), SUM(t2.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_rate,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_9MOB), SUM(t2.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_rate,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_12MOB), SUM(t2.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
JOIN MaxBusinessDate AS mbd
  ON t2.BUSINESS_DATE = mbd.max_dt
WHERE
  DATE_TRUNC(t2.DISBURSALDATE, MONTH) IN ('2024-01-01', '2024-02-01', '2024-03-01')
GROUP BY
  disbursal_month
ORDER BY
  disbursal_month","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:07:41.673956+00:00,12,13,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_3MOB), SUM(t1.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_rate, /* MOB 3 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_6MOB), SUM(t1.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_rate, /* MOB 6 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_9MOB), SUM(t1.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_rate, /* MOB 9 Rate for 30+ Delinquency */
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_12MOB), SUM(t1.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_rate /* MOB 12 Rate for 30+ Delinquency */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxDate AS m
WHERE
  t1.BUSINESS_DATE = m.max_business_date
  AND t1.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  disbursal_month
ORDER BY
  disbursal_month ASC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:07:47.670931+00:00,12,14,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t2.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_3MOB), SUM(t2.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_rate_30_plus, /* MOB 3 Rate */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_6MOB), SUM(t2.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_rate_30_plus, /* MOB 6 Rate */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_9MOB), SUM(t2.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_rate_30_plus, /* MOB 9 Rate */
  ROUND(SAFE_DIVIDE(SUM(t2.NR_30_PLUS_12MOB), SUM(t2.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_rate_30_plus /* MOB 12 Rate */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
CROSS JOIN MaxDate AS md
WHERE
  t2.BUSINESS_DATE = md.dt
  AND t2.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  disbursal_month","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:07:57.375202+00:00,12,15,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  DATE_TRUNC(DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_3MOB), SUM(DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_rate, /* MOB 3 Rate */
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_6MOB), SUM(DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_rate, /* MOB 6 Rate */
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_9MOB), SUM(DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_rate, /* MOB 9 Rate */
  ROUND(SAFE_DIVIDE(SUM(NR_30_PLUS_12MOB), SUM(DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_rate /* MOB 12 Rate */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:08:04.526954+00:00,12,16,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_3MOB), SUM(t1.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_rate, /* MOB 3 Rate */
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_6MOB), SUM(t1.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_rate, /* MOB 6 Rate */
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_9MOB), SUM(t1.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_rate, /* MOB 9 Rate */
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_12MOB), SUM(t1.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_rate /* MOB 12 Rate */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxBusinessDate AS m
WHERE
  t1.BUSINESS_DATE = m.max_dt
  AND t1.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:08:11.289995+00:00,12,17,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t1.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_3MOB), SUM(t1.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage, /* MOB 3 Rate */
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_6MOB), SUM(t1.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_percentage, /* MOB 6 Rate */
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_9MOB), SUM(t1.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_percentage, /* MOB 9 Rate */
  ROUND(SAFE_DIVIDE(SUM(t1.NR_30_PLUS_12MOB), SUM(t1.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_percentage /* MOB 12 Rate */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
CROSS JOIN MaxBusinessDate AS mbd
WHERE
  t1.BUSINESS_DATE = mbd.max_dt
  AND t1.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:08:17.352424+00:00,12,18,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage, /* MOB 3 Rate for 30+ DPD */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_percentage, /* MOB 6 Rate for 30+ DPD */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_percentage, /* MOB 9 Rate for 30+ DPD */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_percentage /* MOB 12 Rate for 30+ DPD */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.DISBURSALDATE >= '2024-01-01' AND t.DISBURSALDATE <= '2024-03-31'
GROUP BY
  1
ORDER BY
  1","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:08:31.066321+00:00,12,19,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_30_plus_delinquency_rate,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_30_plus_delinquency_rate,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_30_plus_delinquency_rate,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_30_plus_delinquency_rate
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxBusinessDate AS mbd
WHERE
  t.BUSINESS_DATE = mbd.max_date
  AND t.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  disbursal_month
ORDER BY
  disbursal_month","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:08:39.521771+00:00,12,20,"Show me the Vintage Curve for 30+ Delinquency for loans disbursed in Jan 2024, Feb 2024, and Mar 2024? At MOB = 3, 6, 9, 12.",Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  DATE_TRUNC(t.DISBURSALDATE, MONTH) AS disbursal_month,
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_3MOB), SUM(t.DR_30_PLUS_3MOB)) * 100, 2) AS mob_3_delinquency_percentage, /* MOB 3 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_6MOB), SUM(t.DR_30_PLUS_6MOB)) * 100, 2) AS mob_6_delinquency_percentage, /* MOB 6 Rate */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_9MOB), SUM(t.DR_30_PLUS_9MOB)) * 100, 2) AS mob_9_delinquency_percentage, /* MOB 9 Rate (assuming NR_30_PLUS_9MOB and DR_30_PLUS_9MOB exist as per common vintage patterns, though not explicitly in schema text) */
  ROUND(SAFE_DIVIDE(SUM(t.NR_30_PLUS_12MOB), SUM(t.DR_30_PLUS_12MOB)) * 100, 2) AS mob_12_delinquency_percentage /* MOB 12 Rate */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxBusinessDate AS mbd
WHERE
  t.BUSINESS_DATE = mbd.max_dt
  AND t.DISBURSALDATE BETWEEN '2024-01-01' AND '2024-03-31'
GROUP BY
  disbursal_month
ORDER BY
  disbursal_month","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:08:44.046083+00:00,13,1,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AGREEMENTNO,
  t.DISBURSALDATE,
  t.MATURITYDATE,
  t.SOM_DPD AS start_of_month_dpd_today,
  t.DPD_BUCKET AS current_dpd_bucket_today,
  t.STATE,
  t.CITY,
  t.MAINSBU,
  t.ASSETNAME
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate
WHERE
  t.BUSINESS_DATE = MaxDate.max_dt
  AND t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:08:48.846117+00:00,13,2,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AGREEMENTNO,
  t.BUSINESS_DATE,
  t.SOM_DPD, /* DPD at start of month for current record (which represents 'today') */
  t.DPD_BUCKET, /* DPD bucket at end of month for current record (which represents 'today') */
  t.Delinquency_0_LY_Flag, /* Flag indicating 0 DPD last year */
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag /* Flag indicating slippage from 0 DPD LY to 90+ DPD current */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.dt
WHERE
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1 AND t.SOM_POS > 0
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:08:53.165409+00:00,13,3,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.0,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS latest_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AGREEMENTNO,
  t.DISBURSALDATE,
  t.BUSINESS_DATE,
  t.SOM_DPD_BUCKET AS dpd_bucket_one_year_ago,
  t.DPD_BUCKET AS current_dpd_bucket
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
INNER JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.latest_business_date
WHERE
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1 AND t.SOM_POS > 0
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:08:57.679107+00:00,13,4,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.AGREEMENTNO,
  t2.DISBURSALDATE,
  t2.STATE,
  t2.SOM_DPD AS som_dpd_current_month,
  t2.DPD_BUCKET AS dpd_bucket_current_month,
  t2.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
INNER JOIN MaxDate
  ON t2.BUSINESS_DATE = MaxDate.dt
WHERE
  t2.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1 AND t2.SOM_POS > 0
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:01.459660+00:00,13,5,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  AGREEMENTNO,
  BUSINESS_DATE,
  SOM_DPD AS som_dpd_current_month,
  DPD_BUCKET AS dpd_bucket_current_month,
  Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:05.068002+00:00,13,6,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  AGREEMENTNO,
  BUSINESS_DATE
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:09.929867+00:00,13,7,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  AGREEMENTNO,
  BUSINESS_DATE,
  SOM_DPD,
  DPD_BUCKET
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:14.073422+00:00,13,8,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AGREEMENTNO,
  t.BUSINESS_DATE,
  t.SOM_DPD AS som_dpd_current,
  t.DPD_BUCKET AS dpd_bucket_current,
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS m
  ON t.BUSINESS_DATE = m.dt
WHERE
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:17.683690+00:00,13,9,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.0,0,0,"SELECT
  AGREEMENTNO,
  BUSINESS_DATE,
  SOM_DPD,
  DPD_BUCKET
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:21.403974+00:00,13,10,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT DISTINCT
  AGREEMENTNO
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:26.072622+00:00,13,11,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AGREEMENTNO,
  t.BUSINESS_DATE,
  t.SOM_DPD AS som_dpd_last_year,
  t.DPD_BUCKET AS dpd_bucket_current,
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:30.390028+00:00,13,12,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AGREEMENTNO,
  t.DISBURSALDATE,
  t.MATURITYDATE,
  t.SOM_DPD AS som_dpd_current_month,
  t.DPD_BUCKET AS dpd_bucket_current_month
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
  AND t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND t.SOM_POS > 0
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:35.017748+00:00,13,13,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  AGREEMENTNO,
  BUSINESS_DATE,
  SOM_DPD AS som_dpd_one_year_ago,
  DPD_BUCKET AS current_dpd_bucket
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:39.537323+00:00,13,14,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AGREEMENTNO,
  t.BUSINESS_DATE,
  t.DPD_BUCKET,
  t.SOM_DPD,
  t.SOM_POS,
  t.STATE,
  t.CITY
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
CROSS JOIN MaxDate
WHERE
  t.BUSINESS_DATE = MaxDate.max_business_date
  AND t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND t.SOM_POS > 0
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:44.769489+00:00,13,15,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  AGREEMENTNO,
  BUSINESS_DATE,
  DPD_BUCKET
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:49.915932+00:00,13,16,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  AGREEMENTNO,
  STATE,
  ZONE,
  CITY,
  DISBURSALDATE,
  MATURITYDATE,
  POS AS current_principal_outstanding,
  DPD_BUCKET AS current_dpd_bucket
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:53.400380+00:00,13,17,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  AGREEMENTNO,
  DISBURSALDATE,
  DPD_BUCKET,
  SOM_DPD,
  STATE,
  CITY
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
  AND SOM_POS > 0
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:09:57.376986+00:00,13,18,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS latest_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.AGREEMENTNO,
  t2.DISBURSALDATE,
  t2.MATURITYDATE,
  t2.STATE,
  t2.CITY,
  t2.SOM_DPD AS current_som_dpd,
  t2.DPD_BUCKET AS current_dpd_bucket,
  t2.POS AS current_pos
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
JOIN MaxDate AS md
  ON t2.BUSINESS_DATE = md.latest_business_date
WHERE
  t2.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1 AND t2.SOM_POS > 0
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:01.674599+00:00,13,19,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AGREEMENTNO,
  t.BUSINESS_DATE,
  t.SOM_DPD, /* To show their DPD last year (implied by the flag) */
  t.DPD_BUCKET /* To show their current DPD bucket (implied by the flag) */
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
INNER JOIN MaxDate
  ON t.BUSINESS_DATE = MaxDate.dt
WHERE
  t.Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:05.379402+00:00,13,20,Identify customers who have 'slipped' significantly: They were 0 DPD exactly one year ago but are 90+ DPD today?,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"SELECT
  AGREEMENTNO,
  BUSINESS_DATE,
  DPD_BUCKET
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
WHERE
  BUSINESS_DATE = (
    SELECT
      MAX(BUSINESS_DATE)
    FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
  )
  AND Delinquency_0LY_90PLUSCurrent_SLIPPAGE_Flag = 1
LIMIT 10","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:09.419228+00:00,14,1,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.0,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_90_PLUS), SUM(t2.POS)) * 100, 2) AS dpd_90_plus_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
INNER JOIN MaxDate AS md
  ON t2.BUSINESS_DATE = md.max_business_date
GROUP BY
  t2.AMTFIN_BAND
ORDER BY
  dpd_90_plus_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:13.813733+00:00,14,2,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(COALESCE(t2.NR_90_PLUS, 0)), SUM(COALESCE(t2.POS, 0))) * 100, 2) AS `90_plus_dpd_pos_percentage`
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
INNER JOIN MaxDate
  ON t2.BUSINESS_DATE = MaxDate.dt
WHERE
  t2.SOM_POS > 0
GROUP BY
  t2.AMTFIN_BAND
ORDER BY
  `90_plus_dpd_pos_percentage` DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:17.480885+00:00,14,3,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
INNER JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.dt
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:21.585994+00:00,14,4,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
INNER JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  NOT t.AMTFIN_BAND IS NULL /* Exclude records where AMTFIN_BAND is null */
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:25.855642+00:00,14,5,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxDate AS md
  ON t.BUSINESS_DATE = md.max_business_date
WHERE
  t.POS > 0 /* Ensure we only consider accounts with outstanding principal */
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:29.874144+00:00,14,6,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:34.326910+00:00,14,7,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(COALESCE(t2.NR_90_PLUS, 0)), SUM(COALESCE(t2.POS, 0))) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
JOIN MaxDate AS md
  ON t2.BUSINESS_DATE = md.max_business_date
WHERE
  t2.SOM_POS > 0
GROUP BY
  t2.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:40.483452+00:00,14,8,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND AS amount_finance_band,
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.SOM_POS > 0 /* Ensure active accounts */
GROUP BY
  amount_finance_band
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:45.395876+00:00,14,9,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t1.AMTFIN_BAND AS amount_finance_band,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_90_PLUS), SUM(t1.POS)) * 100, 2) AS `90_plus_dpd_pos_percentage`
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
WHERE
  t1.BUSINESS_DATE = (
    SELECT
      max_date
    FROM MaxBusinessDate
  )
  AND t1.SOM_POS > 0
GROUP BY
  amount_finance_band
ORDER BY
  `90_plus_dpd_pos_percentage` DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:49.909841+00:00,14,10,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
JOIN MaxBusinessDate AS m
  ON t.BUSINESS_DATE = m.max_dt
WHERE
  t.SOM_POS > 0
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:10:54.480398+00:00,14,11,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t1.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(COALESCE(t1.NR_90_PLUS, 0)), SUM(COALESCE(t1.POS, 0))) * 100, 2) AS `90_plus_dpd_pos_percentage`
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
INNER JOIN MaxDate AS t2
  ON t1.BUSINESS_DATE = t2.max_business_date
GROUP BY
  t1.AMTFIN_BAND
ORDER BY
  `90_plus_dpd_pos_percentage` DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:11:00.966489+00:00,14,12,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(COALESCE(t.NR_90_PLUS, 0)), SUM(COALESCE(t.POS, 0))) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_date
    FROM MaxBusinessDate
  )
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:11:05.321890+00:00,14,13,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxBusinessDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  COALESCE(SUM(t.NR_90_PLUS), 0) AS sum_nr_90_plus_pos,
  COALESCE(SUM(t.POS), 0) AS sum_pos,
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_dt
    FROM MaxBusinessDate
  )
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:11:09.487175+00:00,14,14,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_90_PLUS), SUM(t2.POS)) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
JOIN MaxDate AS m
  ON t2.BUSINESS_DATE = m.dt
WHERE
  t2.POS > 0 /* Ensure active accounts with outstanding principal */
GROUP BY
  t2.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:11:21.683170+00:00,14,15,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      dt
    FROM MaxDate
  )
/* Per ""Risk & NPA Analysis"" rule, DO NOT filter SOM_NPASTAGEID = 'REGULAR' for 90+ DPD. */ /* POS > 0 is implied by SUM(POS) in the denominator and NR_90_PLUS being a POS value. */
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:11:29.344583+00:00,14,16,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t1.AMTFIN_BAND,
  SUM(t1.NR_90_PLUS) AS total_90_plus_dpd_pos,
  SUM(t1.POS) AS total_portfolio_pos,
  ROUND(SAFE_DIVIDE(SUM(t1.NR_90_PLUS), SUM(t1.POS)) * 100, 2) AS `90_plus_dpd_pos_percentage`
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t1
JOIN MaxDate AS md
  ON t1.BUSINESS_DATE = md.max_business_date
WHERE
  t1.SOM_POS > 0 /* Ensure only active accounts are considered for current POS */
GROUP BY
  t1.AMTFIN_BAND
ORDER BY
  `90_plus_dpd_pos_percentage` DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:11:33.783396+00:00,14,17,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
  AND t.POS > 0 /* Ensure we only consider active outstanding balances */
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:11:38.301767+00:00,14,18,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.AMTFIN_BAND,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_90_PLUS), SUM(t2.POS)) * 100, 2) AS dpd_90_plus_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
INNER JOIN MaxDate
  ON t2.BUSINESS_DATE = MaxDate.dt
WHERE
  t2.SOM_POS > 0 /* Ensure active accounts */
GROUP BY
  t2.AMTFIN_BAND
ORDER BY
  dpd_90_plus_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:11:42.098041+00:00,14,19,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.0,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS dt
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t2.AMTFIN_BAND,
  SUM(t2.NR_90_PLUS) AS total_90_plus_pos,
  SUM(t2.POS) AS total_pos,
  ROUND(SAFE_DIVIDE(SUM(t2.NR_90_PLUS), SUM(t2.POS)) * 100, 2) AS dpd_90_plus_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t2
INNER JOIN MaxDate
  ON t2.BUSINESS_DATE = MaxDate.dt
WHERE
  t2.POS > 0 /* Ensure active accounts for POS */
GROUP BY
  t2.AMTFIN_BAND
ORDER BY
  dpd_90_plus_pos_percentage DESC","string indices must be integers, not 'str'"
2ac4c8,2025-11-25 22:11:47.416135+00:00,14,20,Analyze the portfolio risk by Ticket Size: Amount Finance and show the 90+ DPD POS % for each? highest first.,Collections,DomainType.COLLECTIONS,SKIP,Ref Broken,0.01,0,0,"WITH MaxDate AS (
  SELECT
    MAX(BUSINESS_DATE) AS max_business_date
  FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2`
)
SELECT
  t.AMTFIN_BAND,
  SUM(t.NR_90_PLUS) AS total_90_plus_dpd_pos,
  SUM(t.POS) AS total_pos,
  ROUND(SAFE_DIVIDE(SUM(t.NR_90_PLUS), SUM(t.POS)) * 100, 2) AS ninety_plus_dpd_pos_percentage
FROM `analytics-datapipeline-prod.aiml_cj_nostd_mart.TW_COLL_MART_HIST_v2` AS t
WHERE
  t.BUSINESS_DATE = (
    SELECT
      max_business_date
    FROM MaxDate
  )
GROUP BY
  t.AMTFIN_BAND
ORDER BY
  ninety_plus_dpd_pos_percentage DESC","string indices must be integers, not 'str'"
